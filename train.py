"""
è®­ç»ƒè„šæœ¬ - CycleGAN Moneté£æ ¼è½¬æ¢
"""

import os
import random
import numpy as np
import tensorflow as tf
from datetime import datetime

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from config import Config
from data_loader import create_dataset
from models import Generator, Discriminator, CycleGAN
from utils import (
    discriminator_loss, generator_loss, calc_cycle_loss, identity_loss,
    display_samples, display_generated_samples, save_samples, plot_training_history,
    LogCallback
)

def set_seed(seed):
    """è®¾ç½®éšæœºç§å­"""
    random.seed(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)

def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    print("ğŸ¨ CycleGAN Moneté£æ ¼è½¬æ¢è®­ç»ƒ")
    print("=" * 50)
    
    # è®¾ç½®éšæœºç§å­
    set_seed(Config.SEED)
    
    # æ‰“å°é…ç½®
    Config.print_config()
    
    # æ£€æŸ¥GPU
    gpus = tf.config.list_physical_devices('GPU')
    if gpus:
        print(f"âœ“ æ£€æµ‹åˆ° {len(gpus)} ä¸ªGPU")
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
        except RuntimeError as e:
            print(f"GPUé…ç½®é”™è¯¯: {e}")
    else:
        print("âš  æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUï¼ˆé€Ÿåº¦ä¼šå¾ˆæ…¢ï¼‰")
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    save_dir = os.path.join(Config.SAVE_DIR, f"{Config.MODEL_NAME}_{timestamp}")
    os.makedirs(save_dir, exist_ok=True)
    print(f"æ¨¡å‹å°†ä¿å­˜åˆ°: {save_dir}")
    
    # åŠ è½½æ•°æ®
    print("\nğŸ“ åŠ è½½æ•°æ®...")
    dataset, n_monet, n_photo = create_dataset()
    
    # æ˜¾ç¤ºæ•°æ®æ ·æœ¬
    print("\nğŸ–¼ï¸ æ˜¾ç¤ºæ•°æ®æ ·æœ¬...")
    display_samples(dataset, num_samples=8, title="Monetæ ·æœ¬")
    
    # åˆ›å»ºæ¨¡å‹
    print("\nğŸ—ï¸ åˆ›å»ºæ¨¡å‹...")
    monet_generator = Generator()
    photo_generator = Generator()
    monet_discriminator = Discriminator()
    photo_discriminator = Discriminator()
    
    print(f"ç”Ÿæˆå™¨å‚æ•°é‡: {monet_generator.count_params():,}")
    print(f"åˆ¤åˆ«å™¨å‚æ•°é‡: {monet_discriminator.count_params():,}")
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    print("\nâš™ï¸ é…ç½®ä¼˜åŒ–å™¨...")
    monet_gen_optimizer = tf.keras.optimizers.Adam(Config.LEARNING_RATE, beta_1=Config.BETA_1)
    photo_gen_optimizer = tf.keras.optimizers.Adam(Config.LEARNING_RATE, beta_1=Config.BETA_1)
    monet_disc_optimizer = tf.keras.optimizers.Adam(Config.LEARNING_RATE, beta_1=Config.BETA_1)
    photo_disc_optimizer = tf.keras.optimizers.Adam(Config.LEARNING_RATE, beta_1=Config.BETA_1)
    
    # åˆ›å»ºCycleGANæ¨¡å‹
    cyclegan = CycleGAN(
        monet_generator=monet_generator,
        photo_generator=photo_generator,
        monet_discriminator=monet_discriminator,
        photo_discriminator=photo_discriminator,
        lambda_cycle=Config.LAMBDA_CYCLE
    )
    
    # ç¼–è¯‘æ¨¡å‹
    cyclegan.compile(
        m_gen_optimizer=monet_gen_optimizer,
        p_gen_optimizer=photo_gen_optimizer,
        m_disc_optimizer=monet_disc_optimizer,
        p_disc_optimizer=photo_disc_optimizer,
        gen_loss_fn=generator_loss,
        disc_loss_fn=discriminator_loss,
        cycle_loss_fn=calc_cycle_loss,
        identity_loss_fn=identity_loss
    )
    
    # è®¡ç®—è®­ç»ƒæ­¥æ•°
    steps_per_epoch = max(n_monet, n_photo) // Config.BATCH_SIZE
    print(f"\nğŸ“Š è®­ç»ƒé…ç½®:")
    print(f"æ¯è½®æ­¥æ•°: {steps_per_epoch}")
    print(f"æ€»æ­¥æ•°: {steps_per_epoch * Config.EPOCHS}")
    
    # å¼€å§‹è®­ç»ƒ
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    print("=" * 50)
    
    # åˆ›å»ºå›è°ƒ
    callbacks = [
        LogCallback(log_interval=50),
        tf.keras.callbacks.ModelCheckpoint(
            filepath=os.path.join(save_dir, "checkpoint.h5"),
            save_weights_only=True,
            save_best_only=False,
            verbose=1
        )
    ]
    
    # è®­ç»ƒæ¨¡å‹
    history = cyclegan.fit(
        dataset,
        steps_per_epoch=steps_per_epoch,
        epochs=Config.EPOCHS,
        verbose=Config.VERBOSE,
        callbacks=callbacks
    )
    
    print("\nâœ… è®­ç»ƒå®Œæˆï¼")
    
    # ä¿å­˜æ¨¡å‹
    print("\nğŸ’¾ ä¿å­˜æ¨¡å‹...")
    monet_generator.save(os.path.join(save_dir, "monet_generator.h5"))
    photo_generator.save(os.path.join(save_dir, "photo_generator.h5"))
    monet_discriminator.save(os.path.join(save_dir, "monet_discriminator.h5"))
    photo_discriminator.save(os.path.join(save_dir, "photo_discriminator.h5"))
    
    # ç»˜åˆ¶è®­ç»ƒå†å²
    print("\nğŸ“ˆ ç»˜åˆ¶è®­ç»ƒå†å²...")
    plot_training_history(history)
    
    # æ˜¾ç¤ºç”Ÿæˆæ ·æœ¬
    print("\nğŸ¨ æ˜¾ç¤ºç”Ÿæˆæ ·æœ¬...")
    photo_dataset = dataset.map(lambda x, y: y)  # æå–photoéƒ¨åˆ†
    display_generated_samples(photo_dataset, monet_generator, num_samples=8)
    
    # ä¿å­˜æ ·æœ¬
    if Config.SAVE_SAMPLES:
        print("\nğŸ’¾ ä¿å­˜æ ·æœ¬...")
        samples_dir = os.path.join(save_dir, "samples")
        save_samples(photo_dataset, monet_generator, samples_dir, Config.NUM_SAMPLES_TO_SAVE)
    
    print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼æ¨¡å‹å·²ä¿å­˜åˆ°: {save_dir}")
    print("ä¸‹ä¸€æ­¥: è¿è¡Œ python predict.py ç”Ÿæˆæäº¤æ–‡ä»¶")

if __name__ == "__main__":
    main()


