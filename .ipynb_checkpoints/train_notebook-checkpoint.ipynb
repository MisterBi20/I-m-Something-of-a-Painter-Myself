{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CycleGAN Monet风格转换 - 独立项目\n",
        "\n",
        "这是一个完整的Kaggle GAN竞赛解决方案，从零开始实现CycleGAN模型。\n",
        "\n",
        "## 📋 项目特点\n",
        "\n",
        "- ✅ **完全独立**: 不依赖外部项目\n",
        "- ✅ **中文注释**: 详细的中文说明\n",
        "- ✅ **可视化**: 实时查看训练过程和结果\n",
        "- ✅ **自动保存**: 自动保存模型和样本\n",
        "- ✅ **一键提交**: 自动生成Kaggle提交文件\n",
        "\n",
        "## 🚀 使用说明\n",
        "\n",
        "1. 确保数据已放在 `data/Image_Generation_Data_Kaggle/` 目录\n",
        "2. 按顺序运行所有cells\n",
        "3. 训练完成后自动生成提交文件\n",
        "\n",
        "## 📊 数据说明\n",
        "\n",
        "- **Monet图像**: 300张Monet原画\n",
        "- **Photo图像**: 7038张照片\n",
        "- **格式**: TFRecord文件，256x256像素\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 导入库和设置\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 导入必要的库\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "# 设置随机种子\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# 设置TensorFlow日志级别\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "# 配置matplotlib\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "print(\"✅ 库导入成功！\")\n",
        "print(f\"TensorFlow版本: {tf.__version__}\")\n",
        "\n",
        "# 检查GPU\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(f\"✅ 检测到 {len(gpus)} 个GPU\")\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(f\"GPU配置错误: {e}\")\n",
        "else:\n",
        "    print(\"⚠️ 未检测到GPU，将使用CPU（速度会很慢）\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 配置参数\n",
        "\n",
        "**可以根据需要修改以下参数**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==================== 配置参数 ====================\n",
        "\n",
        "# 数据路径\n",
        "DATA_ROOT = \"data/Image_Generation_Data_Kaggle\"\n",
        "MONET_TFREC_PATH = os.path.join(DATA_ROOT, \"monet_tfrec\")\n",
        "PHOTO_TFREC_PATH = os.path.join(DATA_ROOT, \"photo_tfrec\")\n",
        "\n",
        "# 模型参数\n",
        "IMAGE_SIZE = 256\n",
        "CHANNELS = 3\n",
        "LAMBDA_CYCLE = 10.0\n",
        "LAMBDA_IDENTITY = 0.5\n",
        "\n",
        "# 训练参数\n",
        "BATCH_SIZE = 8          # 批次大小（根据显存调整：4/8/16）\n",
        "EPOCHS = 20             # 训练轮数（推荐：20-50）\n",
        "LEARNING_RATE = 2e-4    # 学习率\n",
        "BETA_1 = 0.5            # Adam优化器参数\n",
        "\n",
        "# 数据增强\n",
        "USE_AUGMENTATION = True\n",
        "AUGMENTATION_PROB = 0.5\n",
        "\n",
        "# 保存设置\n",
        "SAVE_DIR = \"saves\"\n",
        "MODEL_NAME = \"cyclegan_monet\"\n",
        "SAVE_SAMPLES = True\n",
        "NUM_SAMPLES_TO_SAVE = 10\n",
        "\n",
        "# 打印配置\n",
        "print(\"=\" * 50)\n",
        "print(\"训练配置:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"数据路径: {DATA_ROOT}\")\n",
        "print(f\"图像尺寸: {IMAGE_SIZE}x{IMAGE_SIZE}\")\n",
        "print(f\"批次大小: {BATCH_SIZE}\")\n",
        "print(f\"训练轮数: {EPOCHS}\")\n",
        "print(f\"学习率: {LEARNING_RATE}\")\n",
        "print(f\"Cycle Loss权重: {LAMBDA_CYCLE}\")\n",
        "print(f\"使用数据增强: {USE_AUGMENTATION}\")\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 数据加载函数\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def count_data_items(filenames):\n",
        "    \"\"\"计算TFRecord文件中的数据项数量\"\"\"\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    return np.sum(n)\n",
        "\n",
        "def decode_image(image):\n",
        "    \"\"\"解码JPEG图像并归一化到[-1, 1]\"\"\"\n",
        "    image = tf.image.decode_jpeg(image, channels=CHANNELS)\n",
        "    image = (tf.cast(image, tf.float32) / 127.5) - 1\n",
        "    image = tf.reshape(image, [IMAGE_SIZE, IMAGE_SIZE, CHANNELS])\n",
        "    return image\n",
        "\n",
        "def read_tfrecord(example):\n",
        "    \"\"\"读取TFRecord示例\"\"\"\n",
        "    tfrecord_format = {\n",
        "        'image_name': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\n",
        "        'target': tf.io.FixedLenFeature([], tf.string)\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
        "    image = decode_image(example['image'])\n",
        "    return image\n",
        "\n",
        "def load_dataset(filenames):\n",
        "    \"\"\"从TFRecord文件加载数据集\"\"\"\n",
        "    dataset = tf.data.TFRecordDataset(filenames)\n",
        "    dataset = dataset.map(read_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "def augment_image(image):\n",
        "    \"\"\"数据增强\"\"\"\n",
        "    if not USE_AUGMENTATION:\n",
        "        return image\n",
        "    \n",
        "    # 随机水平翻转\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    \n",
        "    # 随机垂直翻转\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    \n",
        "    # 随机旋转（90度倍数）\n",
        "    if tf.random.uniform([]) < AUGMENTATION_PROB:\n",
        "        k = tf.random.uniform([], 0, 4, dtype=tf.int32)\n",
        "        image = tf.image.rot90(image, k)\n",
        "    \n",
        "    return image\n",
        "\n",
        "print(\"✅ 数据加载函数定义完成\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 加载数据\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 获取文件列表\n",
        "monet_files = tf.io.gfile.glob(os.path.join(MONET_TFREC_PATH, \"*.tfrec\"))\n",
        "photo_files = tf.io.gfile.glob(os.path.join(PHOTO_TFREC_PATH, \"*.tfrec\"))\n",
        "\n",
        "print(f\"找到 {len(monet_files)} 个Monet TFRecord文件\")\n",
        "print(f\"找到 {len(photo_files)} 个Photo TFRecord文件\")\n",
        "\n",
        "# 计算数据项数量\n",
        "n_monet = count_data_items(monet_files)\n",
        "n_photo = count_data_items(photo_files)\n",
        "\n",
        "print(f\"Monet图像数量: {n_monet}\")\n",
        "print(f\"Photo图像数量: {n_photo}\")\n",
        "\n",
        "# 加载数据集\n",
        "monet_ds = load_dataset(monet_files)\n",
        "photo_ds = load_dataset(photo_files)\n",
        "\n",
        "# 应用数据增强\n",
        "monet_ds = monet_ds.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "photo_ds = photo_ds.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# 配置数据集\n",
        "monet_ds = monet_ds.shuffle(1000).repeat().batch(BATCH_SIZE, drop_remainder=True)\n",
        "photo_ds = photo_ds.shuffle(1000).repeat().batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "# 缓存和预取\n",
        "monet_ds = monet_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
        "photo_ds = photo_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# 创建配对数据集\n",
        "dataset = tf.data.Dataset.zip((monet_ds, photo_ds))\n",
        "\n",
        "print(\"✅ 数据加载完成\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 可视化数据样本\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 显示Monet样本\n",
        "print(\"Monet样本:\")\n",
        "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, (monet, photo) in enumerate(dataset.take(8)):\n",
        "    axes[i].imshow(monet[0] * 0.5 + 0.5)\n",
        "    axes[i].set_title(f'Monet {i+1}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle('Monet样本')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 显示Photo样本\n",
        "print(\"Photo样本:\")\n",
        "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, (monet, photo) in enumerate(dataset.take(8)):\n",
        "    axes[i].imshow(photo[0] * 0.5 + 0.5)\n",
        "    axes[i].set_title(f'Photo {i+1}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle('Photo样本')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 模型定义\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow_addons as tfa\n",
        "\n",
        "def downsample(filters, size, apply_instancenorm=True, strides=2):\n",
        "    \"\"\"下采样层\"\"\"\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    gamma_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "\n",
        "    result = tf.keras.Sequential()\n",
        "    result.add(tf.keras.layers.Conv2D(filters, size, strides=strides, padding='same',\n",
        "                                     kernel_initializer=initializer, use_bias=False))\n",
        "\n",
        "    if apply_instancenorm:\n",
        "        result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n",
        "\n",
        "    result.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "    return result\n",
        "\n",
        "def upsample(filters, size, apply_dropout=False, strides=2):\n",
        "    \"\"\"上采样层\"\"\"\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    gamma_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "\n",
        "    result = tf.keras.Sequential()\n",
        "    result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=strides, padding='same',\n",
        "                                              kernel_initializer=initializer, use_bias=False))\n",
        "\n",
        "    result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n",
        "\n",
        "    if apply_dropout:\n",
        "        result.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "    result.add(tf.keras.layers.ReLU())\n",
        "\n",
        "    return result\n",
        "\n",
        "def Generator():\n",
        "    \"\"\"生成器（U-Net架构）\"\"\"\n",
        "    inputs = tf.keras.layers.Input(shape=[IMAGE_SIZE, IMAGE_SIZE, CHANNELS])\n",
        "\n",
        "    # 下采样\n",
        "    down_stack = [\n",
        "        downsample(64, 4, apply_instancenorm=False),  # (bs, 128, 128, 64)\n",
        "        downsample(128, 4),                           # (bs, 64, 64, 128)\n",
        "        downsample(256, 4),                           # (bs, 32, 32, 256)\n",
        "        downsample(512, 4),                           # (bs, 16, 16, 512)\n",
        "        downsample(512, 4),                           # (bs, 8, 8, 512)\n",
        "        downsample(512, 4),                           # (bs, 4, 4, 512)\n",
        "        downsample(512, 4),                           # (bs, 2, 2, 512)\n",
        "        downsample(512, 4),                           # (bs, 1, 1, 512)\n",
        "    ]\n",
        "\n",
        "    # 上采样\n",
        "    up_stack = [\n",
        "        upsample(512, 4, apply_dropout=True),  # (bs, 2, 2, 1024)\n",
        "        upsample(512, 4, apply_dropout=True),  # (bs, 4, 4, 1024)\n",
        "        upsample(512, 4, apply_dropout=True),  # (bs, 8, 8, 1024)\n",
        "        upsample(512, 4),                      # (bs, 16, 16, 1024)\n",
        "        upsample(256, 4),                      # (bs, 32, 32, 512)\n",
        "        upsample(128, 4),                      # (bs, 64, 64, 256)\n",
        "        upsample(64, 4),                       # (bs, 128, 128, 128)\n",
        "    ]\n",
        "\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    last = tf.keras.layers.Conv2DTranspose(CHANNELS, 4,\n",
        "                                          strides=2,\n",
        "                                          padding='same',\n",
        "                                          kernel_initializer=initializer,\n",
        "                                          activation='tanh')  # (bs, 256, 256, 3)\n",
        "\n",
        "    x = inputs\n",
        "\n",
        "    # 下采样并保存跳跃连接\n",
        "    skips = []\n",
        "    for down in down_stack:\n",
        "        x = down(x)\n",
        "        skips.append(x)\n",
        "\n",
        "    skips = reversed(skips[:-1])\n",
        "\n",
        "    # 上采样并建立跳跃连接\n",
        "    for up, skip in zip(up_stack, skips):\n",
        "        x = up(x)\n",
        "        x = tf.keras.layers.Concatenate()([x, skip])\n",
        "\n",
        "    x = last(x)\n",
        "\n",
        "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
        "\n",
        "def Discriminator():\n",
        "    \"\"\"判别器（PatchGAN架构）\"\"\"\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    gamma_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "\n",
        "    inp = tf.keras.layers.Input(shape=[IMAGE_SIZE, IMAGE_SIZE, CHANNELS], name='input_image')\n",
        "\n",
        "    x = inp\n",
        "\n",
        "    down1 = downsample(64, 4, False)(x)  # (bs, 128, 128, 64)\n",
        "    down2 = downsample(128, 4)(down1)    # (bs, 64, 64, 128)\n",
        "    down3 = downsample(256, 4)(down2)     # (bs, 32, 32, 256)\n",
        "\n",
        "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (bs, 34, 34, 256)\n",
        "    conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
        "                                 kernel_initializer=initializer,\n",
        "                                 use_bias=False)(zero_pad1)  # (bs, 31, 31, 512)\n",
        "\n",
        "    norm1 = tfa.layers.InstanceNormalization(gamma_initializer=gamma_init)(conv)\n",
        "\n",
        "    leaky_relu = tf.keras.layers.LeakyReLU()(norm1)\n",
        "\n",
        "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (bs, 33, 33, 512)\n",
        "\n",
        "    last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
        "                                 kernel_initializer=initializer)(zero_pad2)  # (bs, 30, 30, 1)\n",
        "\n",
        "    return tf.keras.Model(inputs=inp, outputs=last)\n",
        "\n",
        "print(\"✅ 模型定义完成\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 创建模型\n",
        "print(\"🏗️ 创建模型...\")\n",
        "monet_generator = Generator()\n",
        "photo_generator = Generator()\n",
        "monet_discriminator = Discriminator()\n",
        "photo_discriminator = Discriminator()\n",
        "\n",
        "print(f\"生成器参数量: {monet_generator.count_params():,}\")\n",
        "print(f\"判别器参数量: {monet_discriminator.count_params():,}\")\n",
        "\n",
        "print(\"✅ 模型创建完成\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 损失函数定义\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def discriminator_loss(real, generated):\n",
        "    \"\"\"判别器损失函数\"\"\"\n",
        "    real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(\n",
        "        tf.ones_like(real), real)\n",
        "    generated_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(\n",
        "        tf.zeros_like(generated), generated)\n",
        "    total_disc_loss = real_loss + generated_loss\n",
        "    return total_disc_loss * 0.5\n",
        "\n",
        "def generator_loss(generated):\n",
        "    \"\"\"生成器损失函数\"\"\"\n",
        "    return tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(\n",
        "        tf.ones_like(generated), generated)\n",
        "\n",
        "def calc_cycle_loss(real_image, cycled_image, LAMBDA):\n",
        "    \"\"\"循环一致性损失\"\"\"\n",
        "    loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
        "    return LAMBDA * loss1\n",
        "\n",
        "def identity_loss(real_image, same_image, LAMBDA):\n",
        "    \"\"\"恒等损失\"\"\"\n",
        "    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
        "    return LAMBDA * 0.5 * loss\n",
        "\n",
        "print(\"✅ 损失函数定义完成\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. CycleGAN模型类\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CycleGAN(tf.keras.Model):\n",
        "    \"\"\"CycleGAN模型\"\"\"\n",
        "    \n",
        "    def __init__(self, monet_generator, photo_generator, monet_discriminator, photo_discriminator, lambda_cycle=10.0):\n",
        "        super(CycleGAN, self).__init__()\n",
        "        self.m_gen = monet_generator\n",
        "        self.p_gen = photo_generator\n",
        "        self.m_disc = monet_discriminator\n",
        "        self.p_disc = photo_discriminator\n",
        "        self.lambda_cycle = lambda_cycle\n",
        "\n",
        "    def compile(self, m_gen_optimizer, p_gen_optimizer, m_disc_optimizer, p_disc_optimizer,\n",
        "                gen_loss_fn, disc_loss_fn, cycle_loss_fn, identity_loss_fn):\n",
        "        super(CycleGAN, self).compile()\n",
        "        self.m_gen_optimizer = m_gen_optimizer\n",
        "        self.p_gen_optimizer = p_gen_optimizer\n",
        "        self.m_disc_optimizer = m_disc_optimizer\n",
        "        self.p_disc_optimizer = p_disc_optimizer\n",
        "        self.gen_loss_fn = gen_loss_fn\n",
        "        self.disc_loss_fn = disc_loss_fn\n",
        "        self.cycle_loss_fn = cycle_loss_fn\n",
        "        self.identity_loss_fn = identity_loss_fn\n",
        "\n",
        "    def train_step(self, batch_data):\n",
        "        real_monet, real_photo = batch_data\n",
        "        \n",
        "        batch_size = tf.shape(real_monet)[0]\n",
        "        \n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            # Photo -> Monet -> Photo\n",
        "            fake_monet = self.m_gen(real_photo, training=True)\n",
        "            cycled_photo = self.p_gen(fake_monet, training=True)\n",
        "\n",
        "            # Monet -> Photo -> Monet\n",
        "            fake_photo = self.p_gen(real_monet, training=True)\n",
        "            cycled_monet = self.m_gen(fake_photo, training=True)\n",
        "\n",
        "            # Identity loss\n",
        "            same_monet = self.m_gen(real_monet, training=True)\n",
        "            same_photo = self.p_gen(real_photo, training=True)\n",
        "\n",
        "            # Discriminator outputs\n",
        "            disc_real_monet = self.m_disc(real_monet, training=True)\n",
        "            disc_fake_monet = self.m_disc(fake_monet, training=True)\n",
        "            disc_real_photo = self.p_disc(real_photo, training=True)\n",
        "            disc_fake_photo = self.p_disc(fake_photo, training=True)\n",
        "\n",
        "            # Generator losses\n",
        "            monet_gen_loss = self.gen_loss_fn(disc_fake_monet)\n",
        "            photo_gen_loss = self.gen_loss_fn(disc_fake_photo)\n",
        "\n",
        "            # Cycle consistency loss\n",
        "            total_cycle_loss = (self.cycle_loss_fn(real_monet, cycled_monet, self.lambda_cycle) + \n",
        "                               self.cycle_loss_fn(real_photo, cycled_photo, self.lambda_cycle))\n",
        "\n",
        "            # Identity loss\n",
        "            total_monet_gen_loss = (monet_gen_loss + total_cycle_loss + \n",
        "                                   self.identity_loss_fn(real_monet, same_monet, self.lambda_cycle))\n",
        "            total_photo_gen_loss = (photo_gen_loss + total_cycle_loss + \n",
        "                                   self.identity_loss_fn(real_photo, same_photo, self.lambda_cycle))\n",
        "\n",
        "            # Discriminator losses\n",
        "            monet_disc_loss = self.disc_loss_fn(disc_real_monet, disc_fake_monet)\n",
        "            photo_disc_loss = self.disc_loss_fn(disc_real_photo, disc_fake_photo)\n",
        "\n",
        "        # Calculate gradients\n",
        "        monet_gen_grads = tape.gradient(total_monet_gen_loss, self.m_gen.trainable_variables)\n",
        "        photo_gen_grads = tape.gradient(total_photo_gen_loss, self.p_gen.trainable_variables)\n",
        "        monet_disc_grads = tape.gradient(monet_disc_loss, self.m_disc.trainable_variables)\n",
        "        photo_disc_grads = tape.gradient(photo_disc_loss, self.p_disc.trainable_variables)\n",
        "\n",
        "        # Apply gradients\n",
        "        self.m_gen_optimizer.apply_gradients(zip(monet_gen_grads, self.m_gen.trainable_variables))\n",
        "        self.p_gen_optimizer.apply_gradients(zip(photo_gen_grads, self.p_gen.trainable_variables))\n",
        "        self.m_disc_optimizer.apply_gradients(zip(monet_disc_grads, self.m_disc.trainable_variables))\n",
        "        self.p_disc_optimizer.apply_gradients(zip(photo_disc_grads, self.p_disc.trainable_variables))\n",
        "        \n",
        "        return {\n",
        "            'monet_gen_loss': total_monet_gen_loss,\n",
        "            'photo_gen_loss': total_photo_gen_loss,\n",
        "            'monet_disc_loss': monet_disc_loss,\n",
        "            'photo_disc_loss': photo_disc_loss,\n",
        "            'total_cycle_loss': total_cycle_loss\n",
        "        }\n",
        "\n",
        "print(\"✅ CycleGAN模型类定义完成\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. 创建优化器和编译模型\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 创建优化器\n",
        "print(\"⚙️ 配置优化器...\")\n",
        "monet_gen_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE, beta_1=BETA_1)\n",
        "photo_gen_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE, beta_1=BETA_1)\n",
        "monet_disc_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE, beta_1=BETA_1)\n",
        "photo_disc_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE, beta_1=BETA_1)\n",
        "\n",
        "# 创建CycleGAN模型\n",
        "cyclegan = CycleGAN(\n",
        "    monet_generator=monet_generator,\n",
        "    photo_generator=photo_generator,\n",
        "    monet_discriminator=monet_discriminator,\n",
        "    photo_discriminator=photo_discriminator,\n",
        "    lambda_cycle=LAMBDA_CYCLE\n",
        ")\n",
        "\n",
        "# 编译模型\n",
        "cyclegan.compile(\n",
        "    m_gen_optimizer=monet_gen_optimizer,\n",
        "    p_gen_optimizer=photo_gen_optimizer,\n",
        "    m_disc_optimizer=monet_disc_optimizer,\n",
        "    p_disc_optimizer=photo_disc_optimizer,\n",
        "    gen_loss_fn=generator_loss,\n",
        "    disc_loss_fn=discriminator_loss,\n",
        "    cycle_loss_fn=calc_cycle_loss,\n",
        "    identity_loss_fn=identity_loss\n",
        ")\n",
        "\n",
        "print(\"✅ 模型编译完成\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. 开始训练\n",
        "\n",
        "**训练可能需要较长时间，请耐心等待**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 创建保存目录\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "save_dir = os.path.join(SAVE_DIR, f\"{MODEL_NAME}_{timestamp}\")\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "print(f\"模型将保存到: {save_dir}\")\n",
        "\n",
        "# 计算训练步数\n",
        "steps_per_epoch = max(n_monet, n_photo) // BATCH_SIZE\n",
        "print(f\"每轮步数: {steps_per_epoch}\")\n",
        "print(f\"总步数: {steps_per_epoch * EPOCHS}\")\n",
        "\n",
        "# 创建回调\n",
        "class LogCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, log_interval=50):\n",
        "        super().__init__()\n",
        "        self.log_interval = log_interval\n",
        "    \n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        if batch % self.log_interval == 0:\n",
        "            print(f\"Batch {batch}: \"\n",
        "                  f\"Monet Gen Loss: {logs['monet_gen_loss']:.4f}, \"\n",
        "                  f\"Photo Gen Loss: {logs['photo_gen_loss']:.4f}, \"\n",
        "                  f\"Monet Disc Loss: {logs['monet_disc_loss']:.4f}, \"\n",
        "                  f\"Photo Disc Loss: {logs['photo_disc_loss']:.4f}, \"\n",
        "                  f\"Cycle Loss: {logs['total_cycle_loss']:.4f}\")\n",
        "\n",
        "callbacks = [\n",
        "    LogCallback(log_interval=50),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=os.path.join(save_dir, \"checkpoint.h5\"),\n",
        "        save_weights_only=True,\n",
        "        save_best_only=False,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "# 开始训练\n",
        "print(\"🚀 开始训练...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "history = cyclegan.fit(\n",
        "    dataset,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "print(\"✅ 训练完成！\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. 可视化训练历史\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 绘制训练历史\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "# Generator Loss\n",
        "axes[0, 0].plot(history.history['monet_gen_loss'], label='Monet Gen')\n",
        "axes[0, 0].plot(history.history['photo_gen_loss'], label='Photo Gen')\n",
        "axes[0, 0].set_title('Generator Loss')\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('Loss')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True)\n",
        "\n",
        "# Discriminator Loss\n",
        "axes[0, 1].plot(history.history['monet_disc_loss'], label='Monet Disc')\n",
        "axes[0, 1].plot(history.history['photo_disc_loss'], label='Photo Disc')\n",
        "axes[0, 1].set_title('Discriminator Loss')\n",
        "axes[0, 1].set_xlabel('Epoch')\n",
        "axes[0, 1].set_ylabel('Loss')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True)\n",
        "\n",
        "# Cycle Loss\n",
        "axes[1, 0].plot(history.history['total_cycle_loss'], label='Cycle Loss')\n",
        "axes[1, 0].set_title('Cycle Consistency Loss')\n",
        "axes[1, 0].set_xlabel('Epoch')\n",
        "axes[1, 0].set_ylabel('Loss')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True)\n",
        "\n",
        "# Combined Loss\n",
        "axes[1, 1].plot(history.history['monet_gen_loss'], label='Monet Gen')\n",
        "axes[1, 1].plot(history.history['photo_gen_loss'], label='Photo Gen')\n",
        "axes[1, 1].plot(history.history['monet_disc_loss'], label='Monet Disc')\n",
        "axes[1, 1].plot(history.history['photo_disc_loss'], label='Photo Disc')\n",
        "axes[1, 1].set_title('All Losses')\n",
        "axes[1, 1].set_xlabel('Epoch')\n",
        "axes[1, 1].set_ylabel('Loss')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. 显示生成结果\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 显示生成的样本\n",
        "print(\"🎨 显示生成样本...\")\n",
        "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
        "\n",
        "photo_dataset = dataset.map(lambda x, y: y)  # 提取photo部分\n",
        "\n",
        "for i, photo in enumerate(photo_dataset.take(8)):\n",
        "    # 原始照片\n",
        "    axes[0, i].imshow(photo[0] * 0.5 + 0.5)\n",
        "    axes[0, i].set_title(f'Original {i+1}')\n",
        "    axes[0, i].axis('off')\n",
        "    \n",
        "    # 生成的Monet风格\n",
        "    generated = monet_generator(photo, training=False)\n",
        "    axes[1, i].imshow(generated[0] * 0.5 + 0.5)\n",
        "    axes[1, i].set_title(f'Generated {i+1}')\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "plt.suptitle('Photo to Monet Style Transfer')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. 保存模型\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 保存模型\n",
        "print(\"💾 保存模型...\")\n",
        "monet_generator.save(os.path.join(save_dir, \"monet_generator.h5\"))\n",
        "photo_generator.save(os.path.join(save_dir, \"photo_generator.h5\"))\n",
        "monet_discriminator.save(os.path.join(save_dir, \"monet_discriminator.h5\"))\n",
        "photo_discriminator.save(os.path.join(save_dir, \"photo_discriminator.h5\"))\n",
        "\n",
        "print(\"✅ 模型保存完成\")\n",
        "print(f\"模型保存路径: {save_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. 生成提交文件\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import shutil\n",
        "\n",
        "# 创建预测数据集（单张图像批次）\n",
        "photo_files = tf.io.gfile.glob(os.path.join(PHOTO_TFREC_PATH, \"*.tfrec\"))\n",
        "photo_ds_predict = load_dataset(photo_files)\n",
        "photo_ds_predict = photo_ds_predict.batch(1)  # 单张图像批次\n",
        "\n",
        "# 创建输出目录\n",
        "output_dir = os.path.join(save_dir, \"submission_images\")\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# 生成图像\n",
        "print(\"🎨 生成提交图像...\")\n",
        "count = 0\n",
        "\n",
        "for photo in photo_ds_predict:\n",
        "    # 生成Monet风格图像\n",
        "    generated = monet_generator(photo, training=False)\n",
        "    \n",
        "    # 转换为PIL图像并保存\n",
        "    img_array = (generated[0].numpy() * 127.5 + 127.5).astype(np.uint8)\n",
        "    img = Image.fromarray(img_array)\n",
        "    img.save(os.path.join(output_dir, f'{count+1}.jpg'))\n",
        "    \n",
        "    count += 1\n",
        "    \n",
        "    if count % 100 == 0:\n",
        "        print(f\"已生成 {count} 张图像\")\n",
        "\n",
        "print(f\"总共生成了 {count} 张图像\")\n",
        "\n",
        "# 创建ZIP文件\n",
        "zip_path = shutil.make_archive(output_dir, 'zip', output_dir)\n",
        "zip_size = os.path.getsize(zip_path) / (1024 * 1024)\n",
        "\n",
        "print(f\"ZIP文件已创建: {zip_path}\")\n",
        "print(f\"文件大小: {zip_size:.2f} MB\")\n",
        "\n",
        "# 验证结果\n",
        "if count < 7000:\n",
        "    print(\"⚠️ 警告: 图像数量少于7000张！\")\n",
        "elif count > 10000:\n",
        "    print(\"⚠️ 警告: 图像数量超过10000张！\")\n",
        "else:\n",
        "    print(\"✅ 图像数量符合要求 (7000-10000张)\")\n",
        "\n",
        "print(f\"\\n🎉 提交文件已生成: {zip_path}\")\n",
        "print(\"请将此文件上传到Kaggle竞赛页面\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 完成！\n",
        "\n",
        "你的CycleGAN模型已经训练完成，提交文件已生成！\n",
        "\n",
        "### 📊 训练总结\n",
        "\n",
        "- ✅ 模型训练完成\n",
        "- ✅ 训练历史已可视化\n",
        "- ✅ 生成样本已展示\n",
        "- ✅ 模型已保存\n",
        "- ✅ 提交文件已生成\n",
        "\n",
        "### 🎯 下一步\n",
        "\n",
        "1. 找到生成的ZIP文件（在saves目录下）\n",
        "2. 上传到Kaggle竞赛页面\n",
        "3. 等待评估结果\n",
        "\n",
        "### 💡 优化建议\n",
        "\n",
        "- 如果想获得更好的效果，可以增加训练轮数（EPOCHS）\n",
        "- 可以尝试不同的超参数组合\n",
        "- 可以添加更多的数据增强技术\n",
        "\n",
        "### 📁 文件说明\n",
        "\n",
        "- `monet_generator.h5`: 训练好的Monet生成器\n",
        "- `submission_images.zip`: Kaggle提交文件\n",
        "- `checkpoint.h5`: 训练检查点\n",
        "\n",
        "**祝你竞赛成功！** 🎨🏆\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
