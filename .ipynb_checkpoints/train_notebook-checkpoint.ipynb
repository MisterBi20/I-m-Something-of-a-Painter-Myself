{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CycleGAN Moneté£æ ¼è½¬æ¢ - ç‹¬ç«‹é¡¹ç›®\n",
        "\n",
        "è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„Kaggle GANç«èµ›è§£å†³æ–¹æ¡ˆï¼Œä»é›¶å¼€å§‹å®ç°CycleGANæ¨¡å‹ã€‚\n",
        "\n",
        "## ğŸ“‹ é¡¹ç›®ç‰¹ç‚¹\n",
        "\n",
        "- âœ… **å®Œå…¨ç‹¬ç«‹**: ä¸ä¾èµ–å¤–éƒ¨é¡¹ç›®\n",
        "- âœ… **ä¸­æ–‡æ³¨é‡Š**: è¯¦ç»†çš„ä¸­æ–‡è¯´æ˜\n",
        "- âœ… **å¯è§†åŒ–**: å®æ—¶æŸ¥çœ‹è®­ç»ƒè¿‡ç¨‹å’Œç»“æœ\n",
        "- âœ… **è‡ªåŠ¨ä¿å­˜**: è‡ªåŠ¨ä¿å­˜æ¨¡å‹å’Œæ ·æœ¬\n",
        "- âœ… **ä¸€é”®æäº¤**: è‡ªåŠ¨ç”ŸæˆKaggleæäº¤æ–‡ä»¶\n",
        "\n",
        "## ğŸš€ ä½¿ç”¨è¯´æ˜\n",
        "\n",
        "1. ç¡®ä¿æ•°æ®å·²æ”¾åœ¨ `data/Image_Generation_Data_Kaggle/` ç›®å½•\n",
        "2. æŒ‰é¡ºåºè¿è¡Œæ‰€æœ‰cells\n",
        "3. è®­ç»ƒå®Œæˆåè‡ªåŠ¨ç”Ÿæˆæäº¤æ–‡ä»¶\n",
        "\n",
        "## ğŸ“Š æ•°æ®è¯´æ˜\n",
        "\n",
        "- **Monetå›¾åƒ**: 300å¼ MonetåŸç”»\n",
        "- **Photoå›¾åƒ**: 7038å¼ ç…§ç‰‡\n",
        "- **æ ¼å¼**: TFRecordæ–‡ä»¶ï¼Œ256x256åƒç´ \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. å¯¼å…¥åº“å’Œè®¾ç½®\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¯¼å…¥å¿…è¦çš„åº“\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "# è®¾ç½®éšæœºç§å­\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# è®¾ç½®TensorFlowæ—¥å¿—çº§åˆ«\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "# é…ç½®matplotlib\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "print(\"âœ… åº“å¯¼å…¥æˆåŠŸï¼\")\n",
        "print(f\"TensorFlowç‰ˆæœ¬: {tf.__version__}\")\n",
        "\n",
        "# æ£€æŸ¥GPU\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(f\"âœ… æ£€æµ‹åˆ° {len(gpus)} ä¸ªGPU\")\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(f\"GPUé…ç½®é”™è¯¯: {e}\")\n",
        "else:\n",
        "    print(\"âš ï¸ æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUï¼ˆé€Ÿåº¦ä¼šå¾ˆæ…¢ï¼‰\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. é…ç½®å‚æ•°\n",
        "\n",
        "**å¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹ä»¥ä¸‹å‚æ•°**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==================== é…ç½®å‚æ•° ====================\n",
        "\n",
        "# æ•°æ®è·¯å¾„\n",
        "DATA_ROOT = \"data/Image_Generation_Data_Kaggle\"\n",
        "MONET_TFREC_PATH = os.path.join(DATA_ROOT, \"monet_tfrec\")\n",
        "PHOTO_TFREC_PATH = os.path.join(DATA_ROOT, \"photo_tfrec\")\n",
        "\n",
        "# æ¨¡å‹å‚æ•°\n",
        "IMAGE_SIZE = 256\n",
        "CHANNELS = 3\n",
        "LAMBDA_CYCLE = 10.0\n",
        "LAMBDA_IDENTITY = 0.5\n",
        "\n",
        "# è®­ç»ƒå‚æ•°\n",
        "BATCH_SIZE = 8          # æ‰¹æ¬¡å¤§å°ï¼ˆæ ¹æ®æ˜¾å­˜è°ƒæ•´ï¼š4/8/16ï¼‰\n",
        "EPOCHS = 20             # è®­ç»ƒè½®æ•°ï¼ˆæ¨èï¼š20-50ï¼‰\n",
        "LEARNING_RATE = 2e-4    # å­¦ä¹ ç‡\n",
        "BETA_1 = 0.5            # Adamä¼˜åŒ–å™¨å‚æ•°\n",
        "\n",
        "# æ•°æ®å¢å¼º\n",
        "USE_AUGMENTATION = True\n",
        "AUGMENTATION_PROB = 0.5\n",
        "\n",
        "# ä¿å­˜è®¾ç½®\n",
        "SAVE_DIR = \"saves\"\n",
        "MODEL_NAME = \"cyclegan_monet\"\n",
        "SAVE_SAMPLES = True\n",
        "NUM_SAMPLES_TO_SAVE = 10\n",
        "\n",
        "# æ‰“å°é…ç½®\n",
        "print(\"=\" * 50)\n",
        "print(\"è®­ç»ƒé…ç½®:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"æ•°æ®è·¯å¾„: {DATA_ROOT}\")\n",
        "print(f\"å›¾åƒå°ºå¯¸: {IMAGE_SIZE}x{IMAGE_SIZE}\")\n",
        "print(f\"æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}\")\n",
        "print(f\"è®­ç»ƒè½®æ•°: {EPOCHS}\")\n",
        "print(f\"å­¦ä¹ ç‡: {LEARNING_RATE}\")\n",
        "print(f\"Cycle Lossæƒé‡: {LAMBDA_CYCLE}\")\n",
        "print(f\"ä½¿ç”¨æ•°æ®å¢å¼º: {USE_AUGMENTATION}\")\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. æ•°æ®åŠ è½½å‡½æ•°\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def count_data_items(filenames):\n",
        "    \"\"\"è®¡ç®—TFRecordæ–‡ä»¶ä¸­çš„æ•°æ®é¡¹æ•°é‡\"\"\"\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    return np.sum(n)\n",
        "\n",
        "def decode_image(image):\n",
        "    \"\"\"è§£ç JPEGå›¾åƒå¹¶å½’ä¸€åŒ–åˆ°[-1, 1]\"\"\"\n",
        "    image = tf.image.decode_jpeg(image, channels=CHANNELS)\n",
        "    image = (tf.cast(image, tf.float32) / 127.5) - 1\n",
        "    image = tf.reshape(image, [IMAGE_SIZE, IMAGE_SIZE, CHANNELS])\n",
        "    return image\n",
        "\n",
        "def read_tfrecord(example):\n",
        "    \"\"\"è¯»å–TFRecordç¤ºä¾‹\"\"\"\n",
        "    tfrecord_format = {\n",
        "        'image_name': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\n",
        "        'target': tf.io.FixedLenFeature([], tf.string)\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
        "    image = decode_image(example['image'])\n",
        "    return image\n",
        "\n",
        "def load_dataset(filenames):\n",
        "    \"\"\"ä»TFRecordæ–‡ä»¶åŠ è½½æ•°æ®é›†\"\"\"\n",
        "    dataset = tf.data.TFRecordDataset(filenames)\n",
        "    dataset = dataset.map(read_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "def augment_image(image):\n",
        "    \"\"\"æ•°æ®å¢å¼º\"\"\"\n",
        "    if not USE_AUGMENTATION:\n",
        "        return image\n",
        "    \n",
        "    # éšæœºæ°´å¹³ç¿»è½¬\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    \n",
        "    # éšæœºå‚ç›´ç¿»è½¬\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    \n",
        "    # éšæœºæ—‹è½¬ï¼ˆ90åº¦å€æ•°ï¼‰\n",
        "    if tf.random.uniform([]) < AUGMENTATION_PROB:\n",
        "        k = tf.random.uniform([], 0, 4, dtype=tf.int32)\n",
        "        image = tf.image.rot90(image, k)\n",
        "    \n",
        "    return image\n",
        "\n",
        "print(\"âœ… æ•°æ®åŠ è½½å‡½æ•°å®šä¹‰å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. åŠ è½½æ•°æ®\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è·å–æ–‡ä»¶åˆ—è¡¨\n",
        "monet_files = tf.io.gfile.glob(os.path.join(MONET_TFREC_PATH, \"*.tfrec\"))\n",
        "photo_files = tf.io.gfile.glob(os.path.join(PHOTO_TFREC_PATH, \"*.tfrec\"))\n",
        "\n",
        "print(f\"æ‰¾åˆ° {len(monet_files)} ä¸ªMonet TFRecordæ–‡ä»¶\")\n",
        "print(f\"æ‰¾åˆ° {len(photo_files)} ä¸ªPhoto TFRecordæ–‡ä»¶\")\n",
        "\n",
        "# è®¡ç®—æ•°æ®é¡¹æ•°é‡\n",
        "n_monet = count_data_items(monet_files)\n",
        "n_photo = count_data_items(photo_files)\n",
        "\n",
        "print(f\"Monetå›¾åƒæ•°é‡: {n_monet}\")\n",
        "print(f\"Photoå›¾åƒæ•°é‡: {n_photo}\")\n",
        "\n",
        "# åŠ è½½æ•°æ®é›†\n",
        "monet_ds = load_dataset(monet_files)\n",
        "photo_ds = load_dataset(photo_files)\n",
        "\n",
        "# åº”ç”¨æ•°æ®å¢å¼º\n",
        "monet_ds = monet_ds.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "photo_ds = photo_ds.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# é…ç½®æ•°æ®é›†\n",
        "monet_ds = monet_ds.shuffle(1000).repeat().batch(BATCH_SIZE, drop_remainder=True)\n",
        "photo_ds = photo_ds.shuffle(1000).repeat().batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "# ç¼“å­˜å’Œé¢„å–\n",
        "monet_ds = monet_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
        "photo_ds = photo_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# åˆ›å»ºé…å¯¹æ•°æ®é›†\n",
        "dataset = tf.data.Dataset.zip((monet_ds, photo_ds))\n",
        "\n",
        "print(\"âœ… æ•°æ®åŠ è½½å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. å¯è§†åŒ–æ•°æ®æ ·æœ¬\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æ˜¾ç¤ºMonetæ ·æœ¬\n",
        "print(\"Monetæ ·æœ¬:\")\n",
        "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, (monet, photo) in enumerate(dataset.take(8)):\n",
        "    axes[i].imshow(monet[0] * 0.5 + 0.5)\n",
        "    axes[i].set_title(f'Monet {i+1}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle('Monetæ ·æœ¬')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# æ˜¾ç¤ºPhotoæ ·æœ¬\n",
        "print(\"Photoæ ·æœ¬:\")\n",
        "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, (monet, photo) in enumerate(dataset.take(8)):\n",
        "    axes[i].imshow(photo[0] * 0.5 + 0.5)\n",
        "    axes[i].set_title(f'Photo {i+1}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle('Photoæ ·æœ¬')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. æ¨¡å‹å®šä¹‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow_addons as tfa\n",
        "\n",
        "def downsample(filters, size, apply_instancenorm=True, strides=2):\n",
        "    \"\"\"ä¸‹é‡‡æ ·å±‚\"\"\"\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    gamma_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "\n",
        "    result = tf.keras.Sequential()\n",
        "    result.add(tf.keras.layers.Conv2D(filters, size, strides=strides, padding='same',\n",
        "                                     kernel_initializer=initializer, use_bias=False))\n",
        "\n",
        "    if apply_instancenorm:\n",
        "        result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n",
        "\n",
        "    result.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "    return result\n",
        "\n",
        "def upsample(filters, size, apply_dropout=False, strides=2):\n",
        "    \"\"\"ä¸Šé‡‡æ ·å±‚\"\"\"\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    gamma_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "\n",
        "    result = tf.keras.Sequential()\n",
        "    result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=strides, padding='same',\n",
        "                                              kernel_initializer=initializer, use_bias=False))\n",
        "\n",
        "    result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n",
        "\n",
        "    if apply_dropout:\n",
        "        result.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "    result.add(tf.keras.layers.ReLU())\n",
        "\n",
        "    return result\n",
        "\n",
        "def Generator():\n",
        "    \"\"\"ç”Ÿæˆå™¨ï¼ˆU-Netæ¶æ„ï¼‰\"\"\"\n",
        "    inputs = tf.keras.layers.Input(shape=[IMAGE_SIZE, IMAGE_SIZE, CHANNELS])\n",
        "\n",
        "    # ä¸‹é‡‡æ ·\n",
        "    down_stack = [\n",
        "        downsample(64, 4, apply_instancenorm=False),  # (bs, 128, 128, 64)\n",
        "        downsample(128, 4),                           # (bs, 64, 64, 128)\n",
        "        downsample(256, 4),                           # (bs, 32, 32, 256)\n",
        "        downsample(512, 4),                           # (bs, 16, 16, 512)\n",
        "        downsample(512, 4),                           # (bs, 8, 8, 512)\n",
        "        downsample(512, 4),                           # (bs, 4, 4, 512)\n",
        "        downsample(512, 4),                           # (bs, 2, 2, 512)\n",
        "        downsample(512, 4),                           # (bs, 1, 1, 512)\n",
        "    ]\n",
        "\n",
        "    # ä¸Šé‡‡æ ·\n",
        "    up_stack = [\n",
        "        upsample(512, 4, apply_dropout=True),  # (bs, 2, 2, 1024)\n",
        "        upsample(512, 4, apply_dropout=True),  # (bs, 4, 4, 1024)\n",
        "        upsample(512, 4, apply_dropout=True),  # (bs, 8, 8, 1024)\n",
        "        upsample(512, 4),                      # (bs, 16, 16, 1024)\n",
        "        upsample(256, 4),                      # (bs, 32, 32, 512)\n",
        "        upsample(128, 4),                      # (bs, 64, 64, 256)\n",
        "        upsample(64, 4),                       # (bs, 128, 128, 128)\n",
        "    ]\n",
        "\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    last = tf.keras.layers.Conv2DTranspose(CHANNELS, 4,\n",
        "                                          strides=2,\n",
        "                                          padding='same',\n",
        "                                          kernel_initializer=initializer,\n",
        "                                          activation='tanh')  # (bs, 256, 256, 3)\n",
        "\n",
        "    x = inputs\n",
        "\n",
        "    # ä¸‹é‡‡æ ·å¹¶ä¿å­˜è·³è·ƒè¿æ¥\n",
        "    skips = []\n",
        "    for down in down_stack:\n",
        "        x = down(x)\n",
        "        skips.append(x)\n",
        "\n",
        "    skips = reversed(skips[:-1])\n",
        "\n",
        "    # ä¸Šé‡‡æ ·å¹¶å»ºç«‹è·³è·ƒè¿æ¥\n",
        "    for up, skip in zip(up_stack, skips):\n",
        "        x = up(x)\n",
        "        x = tf.keras.layers.Concatenate()([x, skip])\n",
        "\n",
        "    x = last(x)\n",
        "\n",
        "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
        "\n",
        "def Discriminator():\n",
        "    \"\"\"åˆ¤åˆ«å™¨ï¼ˆPatchGANæ¶æ„ï¼‰\"\"\"\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    gamma_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "\n",
        "    inp = tf.keras.layers.Input(shape=[IMAGE_SIZE, IMAGE_SIZE, CHANNELS], name='input_image')\n",
        "\n",
        "    x = inp\n",
        "\n",
        "    down1 = downsample(64, 4, False)(x)  # (bs, 128, 128, 64)\n",
        "    down2 = downsample(128, 4)(down1)    # (bs, 64, 64, 128)\n",
        "    down3 = downsample(256, 4)(down2)     # (bs, 32, 32, 256)\n",
        "\n",
        "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (bs, 34, 34, 256)\n",
        "    conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
        "                                 kernel_initializer=initializer,\n",
        "                                 use_bias=False)(zero_pad1)  # (bs, 31, 31, 512)\n",
        "\n",
        "    norm1 = tfa.layers.InstanceNormalization(gamma_initializer=gamma_init)(conv)\n",
        "\n",
        "    leaky_relu = tf.keras.layers.LeakyReLU()(norm1)\n",
        "\n",
        "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (bs, 33, 33, 512)\n",
        "\n",
        "    last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
        "                                 kernel_initializer=initializer)(zero_pad2)  # (bs, 30, 30, 1)\n",
        "\n",
        "    return tf.keras.Model(inputs=inp, outputs=last)\n",
        "\n",
        "print(\"âœ… æ¨¡å‹å®šä¹‰å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åˆ›å»ºæ¨¡å‹\n",
        "print(\"ğŸ—ï¸ åˆ›å»ºæ¨¡å‹...\")\n",
        "monet_generator = Generator()\n",
        "photo_generator = Generator()\n",
        "monet_discriminator = Discriminator()\n",
        "photo_discriminator = Discriminator()\n",
        "\n",
        "print(f\"ç”Ÿæˆå™¨å‚æ•°é‡: {monet_generator.count_params():,}\")\n",
        "print(f\"åˆ¤åˆ«å™¨å‚æ•°é‡: {monet_discriminator.count_params():,}\")\n",
        "\n",
        "print(\"âœ… æ¨¡å‹åˆ›å»ºå®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. æŸå¤±å‡½æ•°å®šä¹‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def discriminator_loss(real, generated):\n",
        "    \"\"\"åˆ¤åˆ«å™¨æŸå¤±å‡½æ•°\"\"\"\n",
        "    real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(\n",
        "        tf.ones_like(real), real)\n",
        "    generated_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(\n",
        "        tf.zeros_like(generated), generated)\n",
        "    total_disc_loss = real_loss + generated_loss\n",
        "    return total_disc_loss * 0.5\n",
        "\n",
        "def generator_loss(generated):\n",
        "    \"\"\"ç”Ÿæˆå™¨æŸå¤±å‡½æ•°\"\"\"\n",
        "    return tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(\n",
        "        tf.ones_like(generated), generated)\n",
        "\n",
        "def calc_cycle_loss(real_image, cycled_image, LAMBDA):\n",
        "    \"\"\"å¾ªç¯ä¸€è‡´æ€§æŸå¤±\"\"\"\n",
        "    loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
        "    return LAMBDA * loss1\n",
        "\n",
        "def identity_loss(real_image, same_image, LAMBDA):\n",
        "    \"\"\"æ’ç­‰æŸå¤±\"\"\"\n",
        "    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
        "    return LAMBDA * 0.5 * loss\n",
        "\n",
        "print(\"âœ… æŸå¤±å‡½æ•°å®šä¹‰å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. CycleGANæ¨¡å‹ç±»\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CycleGAN(tf.keras.Model):\n",
        "    \"\"\"CycleGANæ¨¡å‹\"\"\"\n",
        "    \n",
        "    def __init__(self, monet_generator, photo_generator, monet_discriminator, photo_discriminator, lambda_cycle=10.0):\n",
        "        super(CycleGAN, self).__init__()\n",
        "        self.m_gen = monet_generator\n",
        "        self.p_gen = photo_generator\n",
        "        self.m_disc = monet_discriminator\n",
        "        self.p_disc = photo_discriminator\n",
        "        self.lambda_cycle = lambda_cycle\n",
        "\n",
        "    def compile(self, m_gen_optimizer, p_gen_optimizer, m_disc_optimizer, p_disc_optimizer,\n",
        "                gen_loss_fn, disc_loss_fn, cycle_loss_fn, identity_loss_fn):\n",
        "        super(CycleGAN, self).compile()\n",
        "        self.m_gen_optimizer = m_gen_optimizer\n",
        "        self.p_gen_optimizer = p_gen_optimizer\n",
        "        self.m_disc_optimizer = m_disc_optimizer\n",
        "        self.p_disc_optimizer = p_disc_optimizer\n",
        "        self.gen_loss_fn = gen_loss_fn\n",
        "        self.disc_loss_fn = disc_loss_fn\n",
        "        self.cycle_loss_fn = cycle_loss_fn\n",
        "        self.identity_loss_fn = identity_loss_fn\n",
        "\n",
        "    def train_step(self, batch_data):\n",
        "        real_monet, real_photo = batch_data\n",
        "        \n",
        "        batch_size = tf.shape(real_monet)[0]\n",
        "        \n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            # Photo -> Monet -> Photo\n",
        "            fake_monet = self.m_gen(real_photo, training=True)\n",
        "            cycled_photo = self.p_gen(fake_monet, training=True)\n",
        "\n",
        "            # Monet -> Photo -> Monet\n",
        "            fake_photo = self.p_gen(real_monet, training=True)\n",
        "            cycled_monet = self.m_gen(fake_photo, training=True)\n",
        "\n",
        "            # Identity loss\n",
        "            same_monet = self.m_gen(real_monet, training=True)\n",
        "            same_photo = self.p_gen(real_photo, training=True)\n",
        "\n",
        "            # Discriminator outputs\n",
        "            disc_real_monet = self.m_disc(real_monet, training=True)\n",
        "            disc_fake_monet = self.m_disc(fake_monet, training=True)\n",
        "            disc_real_photo = self.p_disc(real_photo, training=True)\n",
        "            disc_fake_photo = self.p_disc(fake_photo, training=True)\n",
        "\n",
        "            # Generator losses\n",
        "            monet_gen_loss = self.gen_loss_fn(disc_fake_monet)\n",
        "            photo_gen_loss = self.gen_loss_fn(disc_fake_photo)\n",
        "\n",
        "            # Cycle consistency loss\n",
        "            total_cycle_loss = (self.cycle_loss_fn(real_monet, cycled_monet, self.lambda_cycle) + \n",
        "                               self.cycle_loss_fn(real_photo, cycled_photo, self.lambda_cycle))\n",
        "\n",
        "            # Identity loss\n",
        "            total_monet_gen_loss = (monet_gen_loss + total_cycle_loss + \n",
        "                                   self.identity_loss_fn(real_monet, same_monet, self.lambda_cycle))\n",
        "            total_photo_gen_loss = (photo_gen_loss + total_cycle_loss + \n",
        "                                   self.identity_loss_fn(real_photo, same_photo, self.lambda_cycle))\n",
        "\n",
        "            # Discriminator losses\n",
        "            monet_disc_loss = self.disc_loss_fn(disc_real_monet, disc_fake_monet)\n",
        "            photo_disc_loss = self.disc_loss_fn(disc_real_photo, disc_fake_photo)\n",
        "\n",
        "        # Calculate gradients\n",
        "        monet_gen_grads = tape.gradient(total_monet_gen_loss, self.m_gen.trainable_variables)\n",
        "        photo_gen_grads = tape.gradient(total_photo_gen_loss, self.p_gen.trainable_variables)\n",
        "        monet_disc_grads = tape.gradient(monet_disc_loss, self.m_disc.trainable_variables)\n",
        "        photo_disc_grads = tape.gradient(photo_disc_loss, self.p_disc.trainable_variables)\n",
        "\n",
        "        # Apply gradients\n",
        "        self.m_gen_optimizer.apply_gradients(zip(monet_gen_grads, self.m_gen.trainable_variables))\n",
        "        self.p_gen_optimizer.apply_gradients(zip(photo_gen_grads, self.p_gen.trainable_variables))\n",
        "        self.m_disc_optimizer.apply_gradients(zip(monet_disc_grads, self.m_disc.trainable_variables))\n",
        "        self.p_disc_optimizer.apply_gradients(zip(photo_disc_grads, self.p_disc.trainable_variables))\n",
        "        \n",
        "        return {\n",
        "            'monet_gen_loss': total_monet_gen_loss,\n",
        "            'photo_gen_loss': total_photo_gen_loss,\n",
        "            'monet_disc_loss': monet_disc_loss,\n",
        "            'photo_disc_loss': photo_disc_loss,\n",
        "            'total_cycle_loss': total_cycle_loss\n",
        "        }\n",
        "\n",
        "print(\"âœ… CycleGANæ¨¡å‹ç±»å®šä¹‰å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. åˆ›å»ºä¼˜åŒ–å™¨å’Œç¼–è¯‘æ¨¡å‹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åˆ›å»ºä¼˜åŒ–å™¨\n",
        "print(\"âš™ï¸ é…ç½®ä¼˜åŒ–å™¨...\")\n",
        "monet_gen_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE, beta_1=BETA_1)\n",
        "photo_gen_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE, beta_1=BETA_1)\n",
        "monet_disc_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE, beta_1=BETA_1)\n",
        "photo_disc_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE, beta_1=BETA_1)\n",
        "\n",
        "# åˆ›å»ºCycleGANæ¨¡å‹\n",
        "cyclegan = CycleGAN(\n",
        "    monet_generator=monet_generator,\n",
        "    photo_generator=photo_generator,\n",
        "    monet_discriminator=monet_discriminator,\n",
        "    photo_discriminator=photo_discriminator,\n",
        "    lambda_cycle=LAMBDA_CYCLE\n",
        ")\n",
        "\n",
        "# ç¼–è¯‘æ¨¡å‹\n",
        "cyclegan.compile(\n",
        "    m_gen_optimizer=monet_gen_optimizer,\n",
        "    p_gen_optimizer=photo_gen_optimizer,\n",
        "    m_disc_optimizer=monet_disc_optimizer,\n",
        "    p_disc_optimizer=photo_disc_optimizer,\n",
        "    gen_loss_fn=generator_loss,\n",
        "    disc_loss_fn=discriminator_loss,\n",
        "    cycle_loss_fn=calc_cycle_loss,\n",
        "    identity_loss_fn=identity_loss\n",
        ")\n",
        "\n",
        "print(\"âœ… æ¨¡å‹ç¼–è¯‘å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. å¼€å§‹è®­ç»ƒ\n",
        "\n",
        "**è®­ç»ƒå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åˆ›å»ºä¿å­˜ç›®å½•\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "save_dir = os.path.join(SAVE_DIR, f\"{MODEL_NAME}_{timestamp}\")\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "print(f\"æ¨¡å‹å°†ä¿å­˜åˆ°: {save_dir}\")\n",
        "\n",
        "# è®¡ç®—è®­ç»ƒæ­¥æ•°\n",
        "steps_per_epoch = max(n_monet, n_photo) // BATCH_SIZE\n",
        "print(f\"æ¯è½®æ­¥æ•°: {steps_per_epoch}\")\n",
        "print(f\"æ€»æ­¥æ•°: {steps_per_epoch * EPOCHS}\")\n",
        "\n",
        "# åˆ›å»ºå›è°ƒ\n",
        "class LogCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, log_interval=50):\n",
        "        super().__init__()\n",
        "        self.log_interval = log_interval\n",
        "    \n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        if batch % self.log_interval == 0:\n",
        "            print(f\"Batch {batch}: \"\n",
        "                  f\"Monet Gen Loss: {logs['monet_gen_loss']:.4f}, \"\n",
        "                  f\"Photo Gen Loss: {logs['photo_gen_loss']:.4f}, \"\n",
        "                  f\"Monet Disc Loss: {logs['monet_disc_loss']:.4f}, \"\n",
        "                  f\"Photo Disc Loss: {logs['photo_disc_loss']:.4f}, \"\n",
        "                  f\"Cycle Loss: {logs['total_cycle_loss']:.4f}\")\n",
        "\n",
        "callbacks = [\n",
        "    LogCallback(log_interval=50),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=os.path.join(save_dir, \"checkpoint.h5\"),\n",
        "        save_weights_only=True,\n",
        "        save_best_only=False,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "# å¼€å§‹è®­ç»ƒ\n",
        "print(\"ğŸš€ å¼€å§‹è®­ç»ƒ...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "history = cyclegan.fit(\n",
        "    dataset,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "print(\"âœ… è®­ç»ƒå®Œæˆï¼\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. å¯è§†åŒ–è®­ç»ƒå†å²\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ç»˜åˆ¶è®­ç»ƒå†å²\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "# Generator Loss\n",
        "axes[0, 0].plot(history.history['monet_gen_loss'], label='Monet Gen')\n",
        "axes[0, 0].plot(history.history['photo_gen_loss'], label='Photo Gen')\n",
        "axes[0, 0].set_title('Generator Loss')\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('Loss')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True)\n",
        "\n",
        "# Discriminator Loss\n",
        "axes[0, 1].plot(history.history['monet_disc_loss'], label='Monet Disc')\n",
        "axes[0, 1].plot(history.history['photo_disc_loss'], label='Photo Disc')\n",
        "axes[0, 1].set_title('Discriminator Loss')\n",
        "axes[0, 1].set_xlabel('Epoch')\n",
        "axes[0, 1].set_ylabel('Loss')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True)\n",
        "\n",
        "# Cycle Loss\n",
        "axes[1, 0].plot(history.history['total_cycle_loss'], label='Cycle Loss')\n",
        "axes[1, 0].set_title('Cycle Consistency Loss')\n",
        "axes[1, 0].set_xlabel('Epoch')\n",
        "axes[1, 0].set_ylabel('Loss')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True)\n",
        "\n",
        "# Combined Loss\n",
        "axes[1, 1].plot(history.history['monet_gen_loss'], label='Monet Gen')\n",
        "axes[1, 1].plot(history.history['photo_gen_loss'], label='Photo Gen')\n",
        "axes[1, 1].plot(history.history['monet_disc_loss'], label='Monet Disc')\n",
        "axes[1, 1].plot(history.history['photo_disc_loss'], label='Photo Disc')\n",
        "axes[1, 1].set_title('All Losses')\n",
        "axes[1, 1].set_xlabel('Epoch')\n",
        "axes[1, 1].set_ylabel('Loss')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. æ˜¾ç¤ºç”Ÿæˆç»“æœ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æ˜¾ç¤ºç”Ÿæˆçš„æ ·æœ¬\n",
        "print(\"ğŸ¨ æ˜¾ç¤ºç”Ÿæˆæ ·æœ¬...\")\n",
        "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
        "\n",
        "photo_dataset = dataset.map(lambda x, y: y)  # æå–photoéƒ¨åˆ†\n",
        "\n",
        "for i, photo in enumerate(photo_dataset.take(8)):\n",
        "    # åŸå§‹ç…§ç‰‡\n",
        "    axes[0, i].imshow(photo[0] * 0.5 + 0.5)\n",
        "    axes[0, i].set_title(f'Original {i+1}')\n",
        "    axes[0, i].axis('off')\n",
        "    \n",
        "    # ç”Ÿæˆçš„Moneté£æ ¼\n",
        "    generated = monet_generator(photo, training=False)\n",
        "    axes[1, i].imshow(generated[0] * 0.5 + 0.5)\n",
        "    axes[1, i].set_title(f'Generated {i+1}')\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "plt.suptitle('Photo to Monet Style Transfer')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. ä¿å­˜æ¨¡å‹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ä¿å­˜æ¨¡å‹\n",
        "print(\"ğŸ’¾ ä¿å­˜æ¨¡å‹...\")\n",
        "monet_generator.save(os.path.join(save_dir, \"monet_generator.h5\"))\n",
        "photo_generator.save(os.path.join(save_dir, \"photo_generator.h5\"))\n",
        "monet_discriminator.save(os.path.join(save_dir, \"monet_discriminator.h5\"))\n",
        "photo_discriminator.save(os.path.join(save_dir, \"photo_discriminator.h5\"))\n",
        "\n",
        "print(\"âœ… æ¨¡å‹ä¿å­˜å®Œæˆ\")\n",
        "print(f\"æ¨¡å‹ä¿å­˜è·¯å¾„: {save_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. ç”Ÿæˆæäº¤æ–‡ä»¶\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import shutil\n",
        "\n",
        "# åˆ›å»ºé¢„æµ‹æ•°æ®é›†ï¼ˆå•å¼ å›¾åƒæ‰¹æ¬¡ï¼‰\n",
        "photo_files = tf.io.gfile.glob(os.path.join(PHOTO_TFREC_PATH, \"*.tfrec\"))\n",
        "photo_ds_predict = load_dataset(photo_files)\n",
        "photo_ds_predict = photo_ds_predict.batch(1)  # å•å¼ å›¾åƒæ‰¹æ¬¡\n",
        "\n",
        "# åˆ›å»ºè¾“å‡ºç›®å½•\n",
        "output_dir = os.path.join(save_dir, \"submission_images\")\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ç”Ÿæˆå›¾åƒ\n",
        "print(\"ğŸ¨ ç”Ÿæˆæäº¤å›¾åƒ...\")\n",
        "count = 0\n",
        "\n",
        "for photo in photo_ds_predict:\n",
        "    # ç”ŸæˆMoneté£æ ¼å›¾åƒ\n",
        "    generated = monet_generator(photo, training=False)\n",
        "    \n",
        "    # è½¬æ¢ä¸ºPILå›¾åƒå¹¶ä¿å­˜\n",
        "    img_array = (generated[0].numpy() * 127.5 + 127.5).astype(np.uint8)\n",
        "    img = Image.fromarray(img_array)\n",
        "    img.save(os.path.join(output_dir, f'{count+1}.jpg'))\n",
        "    \n",
        "    count += 1\n",
        "    \n",
        "    if count % 100 == 0:\n",
        "        print(f\"å·²ç”Ÿæˆ {count} å¼ å›¾åƒ\")\n",
        "\n",
        "print(f\"æ€»å…±ç”Ÿæˆäº† {count} å¼ å›¾åƒ\")\n",
        "\n",
        "# åˆ›å»ºZIPæ–‡ä»¶\n",
        "zip_path = shutil.make_archive(output_dir, 'zip', output_dir)\n",
        "zip_size = os.path.getsize(zip_path) / (1024 * 1024)\n",
        "\n",
        "print(f\"ZIPæ–‡ä»¶å·²åˆ›å»º: {zip_path}\")\n",
        "print(f\"æ–‡ä»¶å¤§å°: {zip_size:.2f} MB\")\n",
        "\n",
        "# éªŒè¯ç»“æœ\n",
        "if count < 7000:\n",
        "    print(\"âš ï¸ è­¦å‘Š: å›¾åƒæ•°é‡å°‘äº7000å¼ ï¼\")\n",
        "elif count > 10000:\n",
        "    print(\"âš ï¸ è­¦å‘Š: å›¾åƒæ•°é‡è¶…è¿‡10000å¼ ï¼\")\n",
        "else:\n",
        "    print(\"âœ… å›¾åƒæ•°é‡ç¬¦åˆè¦æ±‚ (7000-10000å¼ )\")\n",
        "\n",
        "print(f\"\\nğŸ‰ æäº¤æ–‡ä»¶å·²ç”Ÿæˆ: {zip_path}\")\n",
        "print(\"è¯·å°†æ­¤æ–‡ä»¶ä¸Šä¼ åˆ°Kaggleç«èµ›é¡µé¢\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## å®Œæˆï¼\n",
        "\n",
        "ä½ çš„CycleGANæ¨¡å‹å·²ç»è®­ç»ƒå®Œæˆï¼Œæäº¤æ–‡ä»¶å·²ç”Ÿæˆï¼\n",
        "\n",
        "### ğŸ“Š è®­ç»ƒæ€»ç»“\n",
        "\n",
        "- âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ\n",
        "- âœ… è®­ç»ƒå†å²å·²å¯è§†åŒ–\n",
        "- âœ… ç”Ÿæˆæ ·æœ¬å·²å±•ç¤º\n",
        "- âœ… æ¨¡å‹å·²ä¿å­˜\n",
        "- âœ… æäº¤æ–‡ä»¶å·²ç”Ÿæˆ\n",
        "\n",
        "### ğŸ¯ ä¸‹ä¸€æ­¥\n",
        "\n",
        "1. æ‰¾åˆ°ç”Ÿæˆçš„ZIPæ–‡ä»¶ï¼ˆåœ¨savesç›®å½•ä¸‹ï¼‰\n",
        "2. ä¸Šä¼ åˆ°Kaggleç«èµ›é¡µé¢\n",
        "3. ç­‰å¾…è¯„ä¼°ç»“æœ\n",
        "\n",
        "### ğŸ’¡ ä¼˜åŒ–å»ºè®®\n",
        "\n",
        "- å¦‚æœæƒ³è·å¾—æ›´å¥½çš„æ•ˆæœï¼Œå¯ä»¥å¢åŠ è®­ç»ƒè½®æ•°ï¼ˆEPOCHSï¼‰\n",
        "- å¯ä»¥å°è¯•ä¸åŒçš„è¶…å‚æ•°ç»„åˆ\n",
        "- å¯ä»¥æ·»åŠ æ›´å¤šçš„æ•°æ®å¢å¼ºæŠ€æœ¯\n",
        "\n",
        "### ğŸ“ æ–‡ä»¶è¯´æ˜\n",
        "\n",
        "- `monet_generator.h5`: è®­ç»ƒå¥½çš„Monetç”Ÿæˆå™¨\n",
        "- `submission_images.zip`: Kaggleæäº¤æ–‡ä»¶\n",
        "- `checkpoint.h5`: è®­ç»ƒæ£€æŸ¥ç‚¹\n",
        "\n",
        "**ç¥ä½ ç«èµ›æˆåŠŸï¼** ğŸ¨ğŸ†\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
