{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kaggle GAN Getting Started - æäº¤Notebook\n",
        "\n",
        "æœ¬notebookç”¨äºåœ¨Kaggleå¹³å°ä¸Šç”ŸæˆMoneté£æ ¼çš„å›¾åƒå¹¶åˆ›å»ºæäº¤æ–‡ä»¶ã€‚\n",
        "\n",
        "## ğŸ“‹ ä½¿ç”¨è¯´æ˜\n",
        "\n",
        "1. **ä¸Šä¼ æ¨¡å‹**: å°†è®­ç»ƒå¥½çš„æ¨¡å‹ä¸Šä¼ åˆ°Kaggle Dataset\n",
        "2. **ä¿®æ”¹è·¯å¾„**: æ›´æ–°ä¸‹é¢çš„MODEL_PATHå˜é‡\n",
        "3. **è¿è¡Œ**: æŒ‰é¡ºåºè¿è¡Œæ‰€æœ‰cells\n",
        "4. **ä¸‹è½½**: ä¸‹è½½ç”Ÿæˆçš„images.zipæ–‡ä»¶\n",
        "\n",
        "## âš ï¸ é‡è¦æç¤º\n",
        "\n",
        "- ç¡®ä¿æ¨¡å‹è·¯å¾„æ­£ç¡®\n",
        "- ç”Ÿæˆçš„å›¾åƒæ•°é‡åº”è¯¥åœ¨7000-10000å¼ ä¹‹é—´\n",
        "- å›¾åƒæ ¼å¼ä¸ºJPGï¼Œå°ºå¯¸256x256\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. å¯¼å…¥åº“å’Œè®¾ç½®\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¯¼å…¥å¿…è¦çš„åº“\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import PIL\n",
        "import shutil\n",
        "\n",
        "# è®¾ç½®TensorFlowæ—¥å¿—çº§åˆ«\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "print(f\"TensorFlowç‰ˆæœ¬: {tf.__version__}\")\n",
        "print(f\"GPUå¯ç”¨: {tf.config.list_physical_devices('GPU')}\")\n",
        "\n",
        "# é…ç½®å‚æ•°\n",
        "HEIGHT, WIDTH, CHANNELS = 256, 256, 3\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "print(\"âœ… åº“å¯¼å…¥å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. é…ç½®æ¨¡å‹è·¯å¾„\n",
        "\n",
        "**âš ï¸ é‡è¦ï¼šè¯·ä¿®æ”¹MODEL_PATHä¸ºä½ ä¸Šä¼ çš„æ¨¡å‹è·¯å¾„ï¼**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===== è¯·ä¿®æ”¹ä¸ºä½ çš„æ¨¡å‹è·¯å¾„ =====\n",
        "MODEL_PATH = \"../input/your-model-dataset/monet_generator.h5\"\n",
        "# =================================\n",
        "\n",
        "print(f\"æ¨¡å‹è·¯å¾„: {MODEL_PATH}\")\n",
        "\n",
        "# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
        "if os.path.exists(MODEL_PATH):\n",
        "    print(\"âœ… æ¨¡å‹æ–‡ä»¶å­˜åœ¨\")\n",
        "else:\n",
        "    print(\"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼\")\n",
        "    print(\"è¯·ç¡®ä¿ï¼š\")\n",
        "    print(\"1. å·²å°†æ¨¡å‹ä¸Šä¼ åˆ°Kaggle Dataset\")\n",
        "    print(\"2. å·²æ­£ç¡®è®¾ç½®MODEL_PATHå˜é‡\")\n",
        "    print(\"3. æ¨¡å‹æ–‡ä»¶åæ­£ç¡®\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. å®šä¹‰è¾…åŠ©å‡½æ•°\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_data_items(filenames):\n",
        "    \"\"\"è®¡ç®—TFRecordæ–‡ä»¶ä¸­çš„æ•°æ®é¡¹æ•°é‡\"\"\"\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    return np.sum(n)\n",
        "\n",
        "def decode_image(image):\n",
        "    \"\"\"è§£ç JPEGå›¾åƒå¹¶å½’ä¸€åŒ–åˆ°[-1, 1]\"\"\"\n",
        "    image = tf.image.decode_jpeg(image, channels=CHANNELS)\n",
        "    image = (tf.cast(image, tf.float32) / 127.5) - 1\n",
        "    image = tf.reshape(image, [HEIGHT, WIDTH, CHANNELS])\n",
        "    return image\n",
        "\n",
        "def read_tfrecord(example):\n",
        "    \"\"\"è¯»å–TFRecordç¤ºä¾‹\"\"\"\n",
        "    tfrecord_format = {\n",
        "        'image_name': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\n",
        "        'target': tf.io.FixedLenFeature([], tf.string)\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
        "    image = decode_image(example['image'])\n",
        "    return image\n",
        "\n",
        "def load_dataset(filenames):\n",
        "    \"\"\"ä»TFRecordæ–‡ä»¶åŠ è½½æ•°æ®é›†\"\"\"\n",
        "    dataset = tf.data.TFRecordDataset(filenames)\n",
        "    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n",
        "    return dataset\n",
        "\n",
        "print(\"âœ… è¾…åŠ©å‡½æ•°å®šä¹‰å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. åŠ è½½æ•°æ®\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è·å–æ•°æ®è·¯å¾„\n",
        "GCS_PATH = \"/kaggle/input/gan-getting-started\"\n",
        "PHOTO_FILENAMES = tf.io.gfile.glob(str(GCS_PATH + '/photo_tfrec/*.tfrec'))\n",
        "\n",
        "# è®¡ç®—å’ŒåŠ è½½æ•°æ®\n",
        "n_photo_samples = count_data_items(PHOTO_FILENAMES)\n",
        "photo_ds = load_dataset(PHOTO_FILENAMES)\n",
        "\n",
        "print(f\"æ‰¾åˆ° {len(PHOTO_FILENAMES)} ä¸ªPhoto TFRecordæ–‡ä»¶\")\n",
        "print(f\"æ€»Photoæ ·æœ¬æ•°: {n_photo_samples}\")\n",
        "\n",
        "# é…ç½®æ•°æ®é›†\n",
        "photo_ds = photo_ds.batch(1)  # å•å¼ å›¾åƒæ‰¹æ¬¡\n",
        "\n",
        "print(\"âœ… æ•°æ®åŠ è½½å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. åŠ è½½æ¨¡å‹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åŠ è½½è®­ç»ƒå¥½çš„Monetç”Ÿæˆå™¨\n",
        "print(f\"æ­£åœ¨åŠ è½½æ¨¡å‹: {MODEL_PATH}\")\n",
        "try:\n",
        "    loaded_model = tf.keras.models.load_model(MODEL_PATH)\n",
        "    print(\"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼\")\n",
        "    print(f\"æ¨¡å‹è¾“å…¥å½¢çŠ¶: {loaded_model.input_shape}\")\n",
        "    print(f\"æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {loaded_model.output_shape}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}\")\n",
        "    print(\"è¯·æ£€æŸ¥MODEL_PATHå˜é‡æ˜¯å¦æ­£ç¡®\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. ç”ŸæˆMoneté£æ ¼å›¾åƒ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_and_save(path, input_ds, generator_model):\n",
        "    \"\"\"ç”Ÿæˆå›¾åƒå¹¶ä¿å­˜åˆ°ç£ç›˜\"\"\"\n",
        "    i = 1\n",
        "    total = sum(1 for _ in input_ds)\n",
        "    \n",
        "    for img in tqdm(input_ds, total=total, desc=\"ç”Ÿæˆå›¾åƒ\"):\n",
        "        # ç”Ÿæˆé¢„æµ‹\n",
        "        prediction = generator_model(img, training=False)[0].numpy()\n",
        "        \n",
        "        # ä»[-1, 1]ç¼©æ”¾åˆ°[0, 255]\n",
        "        prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n",
        "        \n",
        "        # ä¿å­˜ä¸ºJPEG\n",
        "        im = PIL.Image.fromarray(prediction)\n",
        "        im.save(os.path.join(path, \"images\", f\"{i}.jpg\"))\n",
        "        i += 1\n",
        "    \n",
        "    return i - 1\n",
        "\n",
        "# åˆ›å»ºè¾“å‡ºç›®å½•\n",
        "output_dir = \"./images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ç”Ÿæˆå›¾åƒ\n",
        "print(\"å¼€å§‹ç”ŸæˆMoneté£æ ¼å›¾åƒ...\")\n",
        "num_generated = predict_and_save(\n",
        "    path=\"./\",\n",
        "    input_ds=photo_ds,\n",
        "    generator_model=loaded_model\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ… ç”Ÿæˆäº† {num_generated} å¼ å›¾åƒ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. åˆ›å»ºæäº¤ZIPæ–‡ä»¶\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åˆ›å»ºZIPå‹ç¼©åŒ…\n",
        "images_path = os.path.join(\"./\", 'images')\n",
        "zip_path = shutil.make_archive(images_path, 'zip', images_path)\n",
        "\n",
        "# ç»Ÿè®¡ä¿¡æ¯\n",
        "num_files = len([name for name in os.listdir(images_path) if os.path.isfile(os.path.join(images_path, name))])\n",
        "zip_size = os.path.getsize(zip_path) / (1024 * 1024)  # å¤§å°ï¼ˆMBï¼‰\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"æäº¤æ‘˜è¦:\")\n",
        "print(f\"  ç”Ÿæˆå›¾åƒæ•°: {num_files}\")\n",
        "print(f\"  ZIPæ–‡ä»¶: {zip_path}\")\n",
        "print(f\"  ZIPå¤§å°: {zip_size:.2f} MB\")\n",
        "print(f\"{'='*50}\")\n",
        "\n",
        "# éªŒè¯\n",
        "if num_files < 7000:\n",
        "    print(\"âš ï¸ è­¦å‘Š: ç”Ÿæˆå›¾åƒå°‘äº7000å¼ ï¼\")\n",
        "elif num_files > 10000:\n",
        "    print(\"âš ï¸ è­¦å‘Š: ç”Ÿæˆå›¾åƒè¶…è¿‡10000å¼ ï¼\")\n",
        "else:\n",
        "    print(\"âœ… å›¾åƒæ•°é‡ç¬¦åˆè¦æ±‚ (7000-10000å¼ )\")\n",
        "\n",
        "print(f\"\\nğŸ‰ æäº¤æ–‡ä»¶å·²åˆ›å»º: {zip_path}\")\n",
        "print(\"è¯·ä¸‹è½½æ­¤æ–‡ä»¶å¹¶ä¸Šä¼ åˆ°ç«èµ›é¡µé¢\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## å®Œæˆï¼\n",
        "\n",
        "### ğŸ“Š æäº¤æ€»ç»“\n",
        "\n",
        "- âœ… æ¨¡å‹åŠ è½½æˆåŠŸ\n",
        "- âœ… å›¾åƒç”Ÿæˆå®Œæˆ\n",
        "- âœ… ZIPæ–‡ä»¶å·²åˆ›å»º\n",
        "- âœ… æ–‡ä»¶æ•°é‡éªŒè¯é€šè¿‡\n",
        "\n",
        "### ğŸ¯ ä¸‹ä¸€æ­¥\n",
        "\n",
        "1. **ä¸‹è½½æ–‡ä»¶**: ç‚¹å‡»å·¦ä¾§æ–‡ä»¶åˆ—è¡¨ä¸­çš„ `images.zip`\n",
        "2. **ä¸Šä¼ æäº¤**: å°†ZIPæ–‡ä»¶ä¸Šä¼ åˆ°ç«èµ›é¡µé¢\n",
        "3. **ç­‰å¾…ç»“æœ**: ç­‰å¾…Kaggleè¯„ä¼°ä½ çš„æäº¤\n",
        "\n",
        "### ğŸ’¡ æç¤º\n",
        "\n",
        "- å¦‚æœå›¾åƒæ•°é‡ä¸ç¬¦åˆè¦æ±‚ï¼Œè¯·æ£€æŸ¥æ•°æ®åŠ è½½æ˜¯å¦æ­£ç¡®\n",
        "- å¦‚æœç”Ÿæˆè´¨é‡ä¸ä½³ï¼Œå¯èƒ½éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹\n",
        "- å¯ä»¥å°è¯•ä¸åŒçš„æ¨¡å‹å‚æ•°æ¥æ”¹å–„æ•ˆæœ\n",
        "\n",
        "**ç¥ä½ ç«èµ›æˆåŠŸï¼** ğŸ¨ğŸ†\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
