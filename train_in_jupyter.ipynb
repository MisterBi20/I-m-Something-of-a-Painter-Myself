{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CycleGAN Monet风格转换 - 完整训练Notebook\n",
        "\n",
        "本notebook用于在Jupyter Lab中训练CycleGAN模型，将照片转换为Monet风格的画作。\n",
        "\n",
        "## 使用说明：\n",
        "1. 确保数据已经放在正确的位置\n",
        "2. 修改下面的配置参数\n",
        "3. 按顺序运行所有cells\n",
        "4. 训练完成后生成提交文件\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 导入必要的库\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 导入必要的库\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import random\n",
        "import logging\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "# 设置随机种子以保证可重复性\n",
        "seed = 2021\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# 设置TensorFlow日志级别（减少输出）\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "# 添加项目路径到系统路径\n",
        "sys.path.append('Something-of-a-Painter')\n",
        "\n",
        "# 从项目导入必要的模块\n",
        "from models import CycleGan\n",
        "from layers.Augmentations import DiffAugment, DataAugment\n",
        "from data_provider.data_factory import data_provider, get_gan_dataset\n",
        "from utils.metrics import (\n",
        "    discriminator_loss, generator_loss, calc_cycle_loss, identity_loss\n",
        ")\n",
        "from utils.tools import (\n",
        "    display_samples, display_augmented_samples, display_generated_samples,\n",
        "    predict_and_save, LogCallback, ClearMemory\n",
        ")\n",
        "\n",
        "# 配置matplotlib显示中文\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "print(\"✓ 所有库导入成功！\")\n",
        "print(f\"TensorFlow 版本: {tf.__version__}\")\n",
        "print(f\"Python 版本: {sys.version}\")\n",
        "\n",
        "# 检查GPU是否可用\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(f\"✓ 检测到 {len(gpus)} 个GPU\")\n",
        "    for i, gpu in enumerate(gpus):\n",
        "        print(f\"  GPU {i}: {gpu}\")\n",
        "else:\n",
        "    print(\"⚠ 未检测到GPU，将使用CPU（速度会很慢）\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 配置参数\n",
        "\n",
        "**请根据你的实际情况修改以下参数！**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==================== 配置类 ====================\n",
        "class Config:\n",
        "    \"\"\"训练配置参数类\"\"\"\n",
        "    \n",
        "    # ========== 数据路径配置 ==========\n",
        "    # 修改为你实际的数据路径\n",
        "    # 数据目录应该包含: gan-getting-started/monet_tfrec/ 和 gan-getting-started/photo_tfrec/\n",
        "    root_path = '../../data/'  # 数据根目录\n",
        "    # 例如: root_path = 'D:/data/kaggle/'\n",
        "    \n",
        "    # ========== 训练参数 ==========\n",
        "    batch_size = 8              # 批次大小（根据显存调整：4/8/16）\n",
        "    train_epochs = 20           # 训练轮数（推荐：20-50）\n",
        "    steps_per_epoch = -1        # 每轮步数（-1表示自动计算）\n",
        "    learning_rate = 2e-4        # 学习率\n",
        "    \n",
        "    # ========== 模型参数 ==========\n",
        "    height = 256                # 图像高度\n",
        "    width = 256                 # 图像宽度\n",
        "    channels = 3                # 图像通道数（RGB）\n",
        "    out_channels = 3            # 输出通道数\n",
        "    lambda_cycle = 10           # Cycle Loss权重\n",
        "    \n",
        "    # ========== 数据增强配置 ==========\n",
        "    ds_augment = False          # 是否使用数据集增强（True/False）\n",
        "    diffaugment = ['color', 'translation', 'cutout']  # DiffAugmentation类型\n",
        "    \n",
        "    # ========== 其他配置 ==========\n",
        "    model_id = 'EXP'            # 模型ID（用于命名保存文件夹）\n",
        "    seed = 2021                 # 随机种子\n",
        "    use_wandb = False           # 是否使用wandb记录（需要先安装wandb）\n",
        "    \n",
        "    # ========== 自动配置（通常不需要修改）==========\n",
        "    checkpoints = 'checkpoints'\n",
        "    auto = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "# 创建配置对象\n",
        "args = Config()\n",
        "\n",
        "# 创建保存目录\n",
        "if args.root_path == '../../data/':\n",
        "    print(\"⚠ 警告：请修改 root_path 为你实际的数据路径！\")\n",
        "    \n",
        "# 打印配置信息\n",
        "print(\"=\" * 60)\n",
        "print(\"训练配置:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"数据路径: {args.root_path}\")\n",
        "print(f\"批次大小: {args.batch_size}\")\n",
        "print(f\"训练轮数: {args.train_epochs}\")\n",
        "print(f\"学习率: {args.learning_rate}\")\n",
        "print(f\"使用数据集增强: {args.ds_augment}\")\n",
        "print(f\"使用DiffAugmentation: {args.diffaugment}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 加载数据\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 配置全局变量（用于数据加载函数）\n",
        "import data_provider.data_factory as data_factory\n",
        "data_factory.HEIGHT = args.height\n",
        "data_factory.WIDTH = args.width\n",
        "data_factory.CHANNELS = args.channels\n",
        "data_factory.AUTO = args.auto\n",
        "\n",
        "# 设置日志\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# 创建模拟的参数对象（用于数据加载）\n",
        "class Args:\n",
        "    def __init__(self, config):\n",
        "        self.height = config.height\n",
        "        self.width = config.width\n",
        "        self.channels = config.channels\n",
        "        self.auto = config.auto\n",
        "        self.root_path = config.root_path\n",
        "        self.batch_size = config.batch_size\n",
        "\n",
        "args_obj = Args(args)\n",
        "\n",
        "# 加载数据\n",
        "print(\"正在加载数据...\")\n",
        "try:\n",
        "    gan_ds, (n_monet, monet_ds), (n_photo, photo_ds) = data_provider(args_obj, logger)\n",
        "    \n",
        "    print(f\"\\n✓ 数据加载成功！\")\n",
        "    print(f\"Monet图像数量: {n_monet}\")\n",
        "    print(f\"Photo图像数量: {n_photo}\")\n",
        "    \n",
        "    # 自动计算steps_per_epoch\n",
        "    if args.steps_per_epoch == -1:\n",
        "        args.steps_per_epoch = max(n_monet, n_photo) // args.batch_size // 4\n",
        "        print(f\"自动设置 steps_per_epoch: {args.steps_per_epoch}\")\n",
        "    else:\n",
        "        print(f\"使用手动设置 steps_per_epoch: {args.steps_per_epoch}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"✗ 数据加载失败: {e}\")\n",
        "    print(\"请检查数据路径是否正确！\")\n",
        "    print(f\"当前路径: {args.root_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 可视化数据样本\n",
        "\n",
        "让我们看看数据的样本，确保数据加载正确。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 显示Monet样本\n",
        "print(\"Monet 样本:\")\n",
        "display_samples(\n",
        "    path=None,  # 不使用文件保存，直接在notebook中显示\n",
        "    name=\"Monet\", \n",
        "    ds=monet_ds.batch(1), \n",
        "    row=2, \n",
        "    col=4\n",
        ")\n",
        "\n",
        "# 显示Photo样本\n",
        "print(\"\\nPhoto 样本:\")\n",
        "display_samples(\n",
        "    path=None,\n",
        "    name=\"Photo\", \n",
        "    ds=photo_ds.batch(1), \n",
        "    row=2, \n",
        "    col=4\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 构建模型\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 创建参数对象用于模型初始化\n",
        "class ModelArgs:\n",
        "    def __init__(self, config):\n",
        "        self.height = config.height\n",
        "        self.width = config.width\n",
        "        self.channels = config.channels\n",
        "        self.out_channels = config.out_channels\n",
        "        self.ds_augment = config.ds_augment\n",
        "        self.cycle_noise = 0\n",
        "        self.model = 'CycleGan'\n",
        "        self.transformer_blocks = 6\n",
        "        self.wandb = config.use_wandb\n",
        "\n",
        "model_args = ModelArgs(args)\n",
        "\n",
        "# 创建数据增强层\n",
        "dsaug_layer = DataAugment(args.height, args.width, args.channels)\n",
        "\n",
        "# 创建生成器和判别器\n",
        "print(\"正在创建模型...\")\n",
        "monet_generator = CycleGan.Model(model_args).m_gen  # Monet生成器\n",
        "photo_generator = CycleGan.Model(model_args).p_gen  # Photo生成器\n",
        "monet_discriminator = CycleGan.Model(model_args).m_disc  # Monet判别器\n",
        "photo_discriminator = CycleGan.Model(model_args).p_disc  # Photo判别器\n",
        "\n",
        "print(\"✓ 模型创建成功！\")\n",
        "print(f\"\\n生成器参数量: {monet_generator.count_params():,}\")\n",
        "print(f\"判别器参数量: {monet_discriminator.count_params():,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 配置优化器和损失函数\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "# 创建优化器\n",
        "# Adam优化器，学习率2e-4，beta_1=0.5（GAN常用配置）\n",
        "monet_generator_optimizer = optimizers.Adam(args.learning_rate, beta_1=0.5)\n",
        "photo_generator_optimizer = optimizers.Adam(args.learning_rate, beta_1=0.5)\n",
        "monet_discriminator_optimizer = optimizers.Adam(args.learning_rate, beta_1=0.5)\n",
        "photo_discriminator_optimizer = optimizers.Adam(args.learning_rate, beta_1=0.5)\n",
        "\n",
        "print(\"✓ 优化器配置完成\")\n",
        "print(f\"学习率: {args.learning_rate}\")\n",
        "print(f\"优化器: Adam (beta_1=0.5)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 创建CycleGAN模型并编译\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 创建CycleGAN模型\n",
        "class CycleGanModel(tf.keras.Model):\n",
        "    \"\"\"CycleGAN模型类\"\"\"\n",
        "    \n",
        "    def __init__(self, dsaug_layer, m_gen, p_gen, m_disc, p_disc, lambda_cycle=10):\n",
        "        super(CycleGanModel, self).__init__()\n",
        "        self.dsaug_layer = dsaug_layer\n",
        "        self.m_gen = m_gen  # Monet生成器\n",
        "        self.p_gen = p_gen  # Photo生成器\n",
        "        self.m_disc = m_disc  # Monet判别器\n",
        "        self.p_disc = p_disc  # Photo判别器\n",
        "        self.lambda_cycle = lambda_cycle\n",
        "        \n",
        "    def compile(self, m_gen_optimizer, p_gen_optimizer, m_disc_optimizer, p_disc_optimizer,\n",
        "                gen_loss_fn, disc_loss_fn, cycle_loss_fn, identity_loss_fn, diffaugment):\n",
        "        super(CycleGanModel, self).compile()\n",
        "        self.m_gen_optimizer = m_gen_optimizer\n",
        "        self.p_gen_optimizer = p_gen_optimizer\n",
        "        self.m_disc_optimizer = m_disc_optimizer\n",
        "        self.p_disc_optimizer = p_disc_optimizer\n",
        "        self.gen_loss_fn = gen_loss_fn\n",
        "        self.disc_loss_fn = disc_loss_fn\n",
        "        self.cycle_loss_fn = cycle_loss_fn\n",
        "        self.identity_loss_fn = identity_loss_fn\n",
        "        self.diffaugment = diffaugment\n",
        "    \n",
        "    def train_step(self, batch_data):\n",
        "        \"\"\"训练步骤\"\"\"\n",
        "        real_monet, real_photo = batch_data\n",
        "        \n",
        "        # 数据增强（如果启用）\n",
        "        if args.ds_augment:\n",
        "            real_monet = self.dsaug_layer(real_monet)\n",
        "            real_photo = self.dsaug_layer(real_photo)\n",
        "        \n",
        "        batch_size = tf.shape(real_monet)[0]\n",
        "        \n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            # Photo -> Monet -> Photo\n",
        "            fake_monet = self.m_gen(real_photo, training=True)\n",
        "            cycled_photo = self.p_gen(fake_monet, training=True)\n",
        "            \n",
        "            # Monet -> Photo -> Monet\n",
        "            fake_photo = self.p_gen(real_monet, training=True)\n",
        "            cycled_monet = self.m_gen(fake_photo, training=True)\n",
        "            \n",
        "            # Identity loss (恒等损失)\n",
        "            same_monet = self.m_gen(real_monet, training=True)\n",
        "            same_photo = self.p_gen(real_photo, training=True)\n",
        "            \n",
        "            # DiffAugmentation (如果启用)\n",
        "            if len(self.diffaugment) != 0:\n",
        "                both_monet = tf.concat([real_monet, fake_monet], axis=0)\n",
        "                aug_monet = DiffAugment(both_monet, self.diffaugment)\n",
        "                real_monet = aug_monet[:batch_size]\n",
        "                fake_monet = aug_monet[batch_size:]\n",
        "            \n",
        "            # 判别器输出\n",
        "            disc_real_monet = self.m_disc(real_monet, training=True)\n",
        "            disc_fake_monet = self.m_disc(fake_monet, training=True)\n",
        "            disc_real_photo = self.p_disc(real_photo, training=True)\n",
        "            disc_fake_photo = self.p_disc(fake_photo, training=True)\n",
        "            \n",
        "            # 计算损失\n",
        "            monet_gen_loss = self.gen_loss_fn(disc_fake_monet)\n",
        "            photo_gen_loss = self.gen_loss_fn(disc_fake_photo)\n",
        "            \n",
        "            total_cycle_loss = (self.cycle_loss_fn(real_monet, cycled_monet, self.lambda_cycle) + \n",
        "                               self.cycle_loss_fn(real_photo, cycled_photo, self.lambda_cycle))\n",
        "            \n",
        "            total_monet_gen_loss = (monet_gen_loss + total_cycle_loss + \n",
        "                                   self.identity_loss_fn(real_monet, same_monet, self.lambda_cycle))\n",
        "            total_photo_gen_loss = (photo_gen_loss + total_cycle_loss + \n",
        "                                   self.identity_loss_fn(real_photo, same_photo, self.lambda_cycle))\n",
        "            \n",
        "            monet_disc_loss = self.disc_loss_fn(disc_real_monet, disc_fake_monet)\n",
        "            photo_disc_loss = self.disc_loss_fn(disc_real_photo, disc_fake_photo)\n",
        "        \n",
        "        # 计算梯度并更新\n",
        "        monet_gen_grads = tape.gradient(total_monet_gen_loss, self.m_gen.trainable_variables)\n",
        "        photo_gen_grads = tape.gradient(total_photo_gen_loss, self.p_gen.trainable_variables)\n",
        "        monet_disc_grads = tape.gradient(monet_disc_loss, self.m_disc.trainable_variables)\n",
        "        photo_disc_grads = tape.gradient(photo_disc_loss, self.p_disc.trainable_variables)\n",
        "        \n",
        "        self.m_gen_optimizer.apply_gradients(zip(monet_gen_grads, self.m_gen.trainable_variables))\n",
        "        self.p_gen_optimizer.apply_gradients(zip(photo_gen_grads, self.p_gen.trainable_variables))\n",
        "        self.m_disc_optimizer.apply_gradients(zip(monet_disc_grads, self.m_disc.trainable_variables))\n",
        "        self.p_disc_optimizer.apply_gradients(zip(photo_disc_grads, self.p_disc.trainable_variables))\n",
        "        \n",
        "        return {\n",
        "            'monet_gen_loss': total_monet_gen_loss,\n",
        "            'photo_gen_loss': total_photo_gen_loss,\n",
        "            'monet_disc_loss': monet_disc_loss,\n",
        "            'photo_disc_loss': photo_disc_loss,\n",
        "            'total_cycle_loss': total_cycle_loss\n",
        "        }\n",
        "\n",
        "# 创建模型实例\n",
        "gan_model = CycleGanModel(\n",
        "    dsaug_layer=dsaug_layer,\n",
        "    m_gen=monet_generator,\n",
        "    p_gen=photo_generator,\n",
        "    m_disc=monet_discriminator,\n",
        "    p_disc=photo_discriminator,\n",
        "    lambda_cycle=args.lambda_cycle\n",
        ")\n",
        "\n",
        "# 编译模型\n",
        "gan_model.compile(\n",
        "    m_gen_optimizer=monet_generator_optimizer,\n",
        "    p_gen_optimizer=photo_generator_optimizer,\n",
        "    m_disc_optimizer=monet_discriminator_optimizer,\n",
        "    p_disc_optimizer=photo_discriminator_optimizer,\n",
        "    gen_loss_fn=generator_loss,\n",
        "    disc_loss_fn=discriminator_loss,\n",
        "    cycle_loss_fn=calc_cycle_loss,\n",
        "    identity_loss_fn=identity_loss,\n",
        "    diffaugment=args.diffaugment\n",
        ")\n",
        "\n",
        "print(\"✓ 模型编译完成！\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 开始训练\n",
        "\n",
        "训练可能需要较长时间，请耐心等待。可以观察loss的变化来判断训练是否正常。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 创建保存目录\n",
        "save_dir = f\"Something-of-a-Painter/saves/{args.model_id}-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "print(f\"模型将保存到: {save_dir}\")\n",
        "\n",
        "# 训练模型\n",
        "print(\"\\n开始训练...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "history = gan_model.fit(\n",
        "    gan_ds,\n",
        "    steps_per_epoch=args.steps_per_epoch,\n",
        "    epochs=args.train_epochs,\n",
        "    verbose=1,\n",
        "    callbacks=[\n",
        "        LogCallback(logger, log_interval=20),  # 每20步打印一次日志\n",
        "        ClearMemory(logger),  # 清理内存\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"\\n✓ 训练完成！\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. 可视化训练损失\n",
        "\n",
        "查看训练过程中的损失变化。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 绘制训练损失\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Generator Loss\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(history.history['monet_gen_loss'], label='Monet Gen Loss')\n",
        "plt.plot(history.history['photo_gen_loss'], label='Photo Gen Loss')\n",
        "plt.title('Generator Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Discriminator Loss\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(history.history['monet_disc_loss'], label='Monet Disc Loss')\n",
        "plt.plot(history.history['photo_disc_loss'], label='Photo Disc Loss')\n",
        "plt.title('Discriminator Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Cycle Loss\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(history.history['total_cycle_loss'], label='Cycle Loss')\n",
        "plt.title('Cycle Consistency Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. 可视化生成结果\n",
        "\n",
        "让我们看看模型生成的Monet风格图像。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 生成并显示样本\n",
        "print(\"生成Monet风格图像样本...\")\n",
        "display_generated_samples(\n",
        "    path=None,  # 直接在notebook中显示\n",
        "    ds=photo_ds.batch(1),\n",
        "    model=monet_generator,\n",
        "    n_samples=6\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. 保存模型\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 保存模型\n",
        "model_save_path = os.path.join(save_dir, \"model_m_gen\")\n",
        "monet_generator.save(model_save_path)\n",
        "print(f\"✓ 模型已保存到: {model_save_path}\")\n",
        "\n",
        "# 也保存checkpoint\n",
        "checkpoint_path = os.path.join(save_dir, \"checkpoints\")\n",
        "os.makedirs(checkpoint_path, exist_ok=True)\n",
        "gan_model.save_weights(os.path.join(checkpoint_path, \"cp.ckpt\"))\n",
        "print(f\"✓ Checkpoint已保存到: {checkpoint_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. 生成提交文件\n",
        "\n",
        "为Kaggle竞赛生成提交文件。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 创建输出目录\n",
        "images_dir = os.path.join(save_dir, \"images\")\n",
        "os.makedirs(images_dir, exist_ok=True)\n",
        "\n",
        "# 生成图像\n",
        "print(\"正在生成提交图像...\")\n",
        "predict_and_save(\n",
        "    path=save_dir,\n",
        "    input_ds=photo_ds.batch(1),\n",
        "    generator_model=monet_generator\n",
        ")\n",
        "\n",
        "# 统计生成的文件\n",
        "num_files = len([f for f in os.listdir(images_dir) if f.endswith('.jpg')])\n",
        "print(f\"\\n✓ 已生成 {num_files} 张图像\")\n",
        "\n",
        "# 创建ZIP文件\n",
        "import shutil\n",
        "zip_path = shutil.make_archive(images_dir, 'zip', images_dir)\n",
        "zip_size = os.path.getsize(zip_path) / (1024 * 1024)\n",
        "\n",
        "print(f\"\\n✓ ZIP文件已创建: {zip_path}\")\n",
        "print(f\"文件大小: {zip_size:.2f} MB\")\n",
        "\n",
        "# 验证\n",
        "if num_files < 7000:\n",
        "    print(\"⚠ 警告: 图像数量少于7000张！\")\n",
        "elif num_files > 10000:\n",
        "    print(\"⚠ 警告: 图像数量超过10000张！\")\n",
        "else:\n",
        "    print(\"✓ 图像数量符合要求 (7000-10000张)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 完成！\n",
        "\n",
        "你的模型已经训练完成，提交文件已生成！\n",
        "\n",
        "### 下一步：\n",
        "1. 找到生成的ZIP文件（在 saves 目录下）\n",
        "2. 上传到Kaggle竞赛页面\n",
        "3. 等待评估结果\n",
        "\n",
        "### 提示：\n",
        "- 如果想训练更长时间以获得更好的效果，可以增加 `train_epochs` 参数\n",
        "- 可以尝试不同的数据增强配置\n",
        "- 记得保存这个notebook和配置\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
