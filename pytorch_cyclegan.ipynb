{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 库导入成功！\n",
      "PyTorch版本: 2.5.1+cu121\n",
      "✅ 检测到 1 个GPU\n",
      "当前GPU: NVIDIA GeForce RTX 5070 Ti\n",
      "使用设备: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Python39\\lib\\site-packages\\torch\\cuda\\__init__.py:235: UserWarning: \n",
      "NVIDIA GeForce RTX 5070 Ti with CUDA capability sm_120 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 sm_90.\n",
      "If you want to use the NVIDIA GeForce RTX 5070 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf  # 仅用于读取TFRecord文件\n",
    "\n",
    "# 设置随机种子\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# 配置matplotlib\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"✅ 库导入成功！\")\n",
    "print(f\"PyTorch版本: {torch.__version__}\")\n",
    "\n",
    "# 检查GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"✅ 检测到 {torch.cuda.device_count()} 个GPU\")\n",
    "    print(f\"当前GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"⚠️ 未检测到GPU，将使用CPU（速度会很慢）\")\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"使用设备: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 配置参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "训练配置:\n",
      "==================================================\n",
      "数据路径: data/Image_Generation_Data_Kaggle\n",
      "图像尺寸: 256x256\n",
      "批次大小: 8\n",
      "训练轮数: 20\n",
      "学习率: 0.0002\n",
      "Cycle Loss权重: 10.0\n",
      "使用数据增强: True\n",
      "使用设备: cuda\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================== 配置参数 ====================\n",
    "\n",
    "# 数据路径\n",
    "DATA_ROOT = \"data/Image_Generation_Data_Kaggle\"\n",
    "MONET_TFREC_PATH = os.path.join(DATA_ROOT, \"monet_tfrec\")\n",
    "PHOTO_TFREC_PATH = os.path.join(DATA_ROOT, \"photo_tfrec\")\n",
    "\n",
    "# 模型参数\n",
    "IMAGE_SIZE = 256\n",
    "CHANNELS = 3\n",
    "LAMBDA_CYCLE = 10.0\n",
    "LAMBDA_IDENTITY = 0.5\n",
    "\n",
    "# 训练参数\n",
    "BATCH_SIZE = 8          # 批次大小（根据显存调整：4/8/16）\n",
    "EPOCHS = 20             # 训练轮数（推荐：20-50）\n",
    "LEARNING_RATE = 2e-4    # 学习率\n",
    "BETA_1 = 0.5            # Adam优化器参数\n",
    "\n",
    "# 数据增强\n",
    "USE_AUGMENTATION = True\n",
    "AUGMENTATION_PROB = 0.5\n",
    "\n",
    "# 保存设置\n",
    "SAVE_DIR = \"saves\"\n",
    "MODEL_NAME = \"pytorch_cyclegan_monet\"\n",
    "SAVE_SAMPLES = True\n",
    "NUM_SAMPLES_TO_SAVE = 10\n",
    "\n",
    "# 打印配置\n",
    "print(\"=\" * 50)\n",
    "print(\"训练配置:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"数据路径: {DATA_ROOT}\")\n",
    "print(f\"图像尺寸: {IMAGE_SIZE}x{IMAGE_SIZE}\")\n",
    "print(f\"批次大小: {BATCH_SIZE}\")\n",
    "print(f\"训练轮数: {EPOCHS}\")\n",
    "print(f\"学习率: {LEARNING_RATE}\")\n",
    "print(f\"Cycle Loss权重: {LAMBDA_CYCLE}\")\n",
    "print(f\"使用数据增强: {USE_AUGMENTATION}\")\n",
    "print(f\"使用设备: {device}\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 数据加载\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到 5 个Monet TFRecord文件\n",
      "找到 20 个Photo TFRecord文件\n",
      "Monet图像数量: 300\n",
      "Photo图像数量: 7038\n",
      "✅ 数据加载完成\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    \"\"\"计算TFRecord文件中的数据项数量\"\"\"\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "def decode_image(image):\n",
    "    \"\"\"解码JPEG图像并归一化到[-1, 1]\"\"\"\n",
    "    image = tf.image.decode_jpeg(image, channels=CHANNELS)\n",
    "    image = (tf.cast(image, tf.float32) / 127.5) - 1\n",
    "    image = tf.reshape(image, [IMAGE_SIZE, IMAGE_SIZE, CHANNELS])\n",
    "    return image\n",
    "\n",
    "def read_tfrecord(example):\n",
    "    \"\"\"读取TFRecord示例\"\"\"\n",
    "    tfrecord_format = {\n",
    "        'image_name': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'target': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
    "    image = decode_image(example['image'])\n",
    "    return image\n",
    "\n",
    "def load_dataset(filenames):\n",
    "    \"\"\"从TFRecord文件加载数据集\"\"\"\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# 获取文件列表\n",
    "monet_files = tf.io.gfile.glob(os.path.join(MONET_TFREC_PATH, \"*.tfrec\"))\n",
    "photo_files = tf.io.gfile.glob(os.path.join(PHOTO_TFREC_PATH, \"*.tfrec\"))\n",
    "\n",
    "print(f\"找到 {len(monet_files)} 个Monet TFRecord文件\")\n",
    "print(f\"找到 {len(photo_files)} 个Photo TFRecord文件\")\n",
    "\n",
    "# 计算数据项数量\n",
    "n_monet = count_data_items(monet_files)\n",
    "n_photo = count_data_items(photo_files)\n",
    "\n",
    "print(f\"Monet图像数量: {n_monet}\")\n",
    "print(f\"Photo图像数量: {n_photo}\")\n",
    "\n",
    "# 加载数据集\n",
    "monet_ds = load_dataset(monet_files)\n",
    "photo_ds = load_dataset(photo_files)\n",
    "\n",
    "print(\"✅ 数据加载完成\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PyTorch数据集类\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建Monet数据集...\n",
      "正在转换数据集...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "转换数据: 300it [00:00, 3536.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建Photo数据集...\n",
      "正在转换数据集...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "转换数据: 7038it [00:03, 1891.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 数据集创建完成\n",
      "Monet数据集大小: 300\n",
      "Photo数据集大小: 7038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class CycleGANDataset(Dataset):\n",
    "    \"\"\"CycleGAN数据集类\"\"\"\n",
    "    \n",
    "    def __init__(self, tf_dataset, transform=None):\n",
    "        self.tf_dataset = tf_dataset\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        \n",
    "        # 将TensorFlow数据集转换为列表\n",
    "        print(\"正在转换数据集...\")\n",
    "        for item in tqdm(tf_dataset, desc=\"转换数据\"):\n",
    "            # 转换为numpy数组\n",
    "            img = item.numpy()\n",
    "            # 转换为PIL图像\n",
    "            img = Image.fromarray((img * 127.5 + 127.5).astype(np.uint8))\n",
    "            self.data.append(img)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img\n",
    "\n",
    "# 数据变换\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # 归一化到[-1, 1]\n",
    "])\n",
    "\n",
    "# 创建PyTorch数据集\n",
    "print(\"创建Monet数据集...\")\n",
    "monet_dataset = CycleGANDataset(monet_ds.take(n_monet), transform)\n",
    "print(\"创建Photo数据集...\")\n",
    "photo_dataset = CycleGANDataset(photo_ds.take(n_photo), transform)\n",
    "\n",
    "# 创建数据加载器\n",
    "monet_loader = DataLoader(monet_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "photo_loader = DataLoader(photo_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "print(f\"✅ 数据集创建完成\")\n",
    "print(f\"Monet数据集大小: {len(monet_dataset)}\")\n",
    "print(f\"Photo数据集大小: {len(photo_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型定义\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建模型...\n",
      "生成器参数量: 7,845,123\n",
      "判别器参数量: 2,766,529\n",
      "✅ 模型创建完成\n"
     ]
    }
   ],
   "source": [
    "class InstanceNorm2d(nn.Module):\n",
    "    \"\"\"Instance Normalization层\"\"\"\n",
    "    def __init__(self, num_features, eps=1e-5, momentum=0.1):\n",
    "        super(InstanceNorm2d, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.ones(num_features))\n",
    "        self.bias = nn.Parameter(torch.zeros(num_features))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 计算均值和方差\n",
    "        mean = x.mean(dim=(2, 3), keepdim=True)\n",
    "        var = x.var(dim=(2, 3), keepdim=True, unbiased=False)\n",
    "        \n",
    "        # 归一化\n",
    "        x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        \n",
    "        # 缩放和偏移\n",
    "        x = x * self.weight.view(1, -1, 1, 1) + self.bias.view(1, -1, 1, 1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"残差块\"\"\"\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, 3, padding=1),\n",
    "            InstanceNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels, in_channels, 3, padding=1),\n",
    "            InstanceNorm2d(in_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"生成器（U-Net架构）\"\"\"\n",
    "    def __init__(self, input_channels=3, output_channels=3, num_residual_blocks=6):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # 初始卷积层\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 64, 7, padding=3),\n",
    "            InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # 下采样\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            InstanceNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
    "            InstanceNorm2d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # 残差块\n",
    "        residual_blocks = []\n",
    "        for _ in range(num_residual_blocks):\n",
    "            residual_blocks.append(ResidualBlock(256))\n",
    "        self.residual_blocks = nn.Sequential(*residual_blocks)\n",
    "        \n",
    "        # 上采样\n",
    "        self.up1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),\n",
    "            InstanceNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.up2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),\n",
    "            InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # 输出层\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Conv2d(64, output_channels, 7, padding=3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 下采样\n",
    "        d1 = self.initial(x)\n",
    "        d2 = self.down1(d1)\n",
    "        d3 = self.down2(d2)\n",
    "        \n",
    "        # 残差块\n",
    "        residual = self.residual_blocks(d3)\n",
    "        \n",
    "        # 上采样\n",
    "        u1 = self.up1(residual)\n",
    "        u2 = self.up2(u1)\n",
    "        \n",
    "        # 输出\n",
    "        output = self.output(u2)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"判别器（PatchGAN架构）\"\"\"\n",
    "    def __init__(self, input_channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            # 第一层\n",
    "            nn.Conv2d(input_channels, 64, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 第二层\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 第三层\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "            InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 第四层\n",
    "            nn.Conv2d(256, 512, 4, stride=2, padding=1),\n",
    "            InstanceNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 输出层\n",
    "            nn.Conv2d(512, 1, 4, padding=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# 创建模型\n",
    "print(\"创建模型...\")\n",
    "monet_generator = Generator().to(device)\n",
    "photo_generator = Generator().to(device)\n",
    "monet_discriminator = Discriminator().to(device)\n",
    "photo_discriminator = Discriminator().to(device)\n",
    "\n",
    "print(f\"生成器参数量: {sum(p.numel() for p in monet_generator.parameters()):,}\")\n",
    "print(f\"判别器参数量: {sum(p.numel() for p in monet_discriminator.parameters()):,}\")\n",
    "print(\"✅ 模型创建完成\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 损失函数和优化器配置完成\n"
     ]
    }
   ],
   "source": [
    "# 损失函数\n",
    "criterion_gan = nn.MSELoss()\n",
    "criterion_cycle = nn.L1Loss()\n",
    "criterion_identity = nn.L1Loss()\n",
    "\n",
    "# 优化器\n",
    "optimizer_G = optim.Adam(\n",
    "    list(monet_generator.parameters()) + list(photo_generator.parameters()),\n",
    "    lr=LEARNING_RATE, betas=(BETA_1, 0.999)\n",
    ")\n",
    "\n",
    "optimizer_D_monet = optim.Adam(monet_discriminator.parameters(), lr=LEARNING_RATE, betas=(BETA_1, 0.999))\n",
    "optimizer_D_photo = optim.Adam(photo_discriminator.parameters(), lr=LEARNING_RATE, betas=(BETA_1, 0.999))\n",
    "\n",
    "# 学习率调度器\n",
    "scheduler_G = optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=lambda epoch: 0.95 ** epoch)\n",
    "scheduler_D_monet = optim.lr_scheduler.LambdaLR(optimizer_D_monet, lr_lambda=lambda epoch: 0.95 ** epoch)\n",
    "scheduler_D_photo = optim.lr_scheduler.LambdaLR(optimizer_D_photo, lr_lambda=lambda epoch: 0.95 ** epoch)\n",
    "\n",
    "print(\"✅ 损失函数和优化器配置完成\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 训练函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 训练函数定义完成\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(monet_loader, photo_loader, epoch):\n",
    "    \"\"\"训练一个epoch\"\"\"\n",
    "    monet_generator.train()\n",
    "    photo_generator.train()\n",
    "    monet_discriminator.train()\n",
    "    photo_discriminator.train()\n",
    "    \n",
    "    total_loss_G = 0\n",
    "    total_loss_D_monet = 0\n",
    "    total_loss_D_photo = 0\n",
    "    \n",
    "    # 创建迭代器\n",
    "    monet_iter = iter(monet_loader)\n",
    "    photo_iter = iter(photo_loader)\n",
    "    \n",
    "    # 计算步数\n",
    "    steps = min(len(monet_loader), len(photo_loader))\n",
    "    \n",
    "    for step in tqdm(range(steps), desc=f\"Epoch {epoch+1}\"):\n",
    "        try:\n",
    "            real_monet = next(monet_iter).to(device)\n",
    "            real_photo = next(photo_iter).to(device)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        \n",
    "        batch_size = real_monet.size(0)\n",
    "        \n",
    "        # 真实和假的标签\n",
    "        real_label = torch.ones(batch_size, 1, 30, 30).to(device)\n",
    "        fake_label = torch.zeros(batch_size, 1, 30, 30).to(device)\n",
    "        \n",
    "        # ==================== 训练生成器 ====================\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        # Identity loss\n",
    "        loss_identity_monet = criterion_identity(monet_generator(real_monet), real_monet)\n",
    "        loss_identity_photo = criterion_identity(photo_generator(real_photo), real_photo)\n",
    "        loss_identity = (loss_identity_monet + loss_identity_photo) * LAMBDA_IDENTITY\n",
    "        \n",
    "        # GAN loss\n",
    "        fake_monet = monet_generator(real_photo)\n",
    "        fake_photo = photo_generator(real_monet)\n",
    "        \n",
    "        pred_fake_monet = monet_discriminator(fake_monet)\n",
    "        pred_fake_photo = photo_discriminator(fake_photo)\n",
    "        \n",
    "        loss_G_monet = criterion_gan(pred_fake_monet, real_label)\n",
    "        loss_G_photo = criterion_gan(pred_fake_photo, real_label)\n",
    "        \n",
    "        # Cycle loss\n",
    "        cycled_monet = monet_generator(fake_photo)\n",
    "        cycled_photo = photo_generator(fake_monet)\n",
    "        \n",
    "        loss_cycle_monet = criterion_cycle(cycled_monet, real_monet)\n",
    "        loss_cycle_photo = criterion_cycle(cycled_photo, real_photo)\n",
    "        loss_cycle = (loss_cycle_monet + loss_cycle_photo) * LAMBDA_CYCLE\n",
    "        \n",
    "        # 总生成器损失\n",
    "        loss_G = loss_G_monet + loss_G_photo + loss_cycle + loss_identity\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # ==================== 训练判别器 ====================\n",
    "        # Monet判别器\n",
    "        optimizer_D_monet.zero_grad()\n",
    "        \n",
    "        pred_real_monet = monet_discriminator(real_monet)\n",
    "        pred_fake_monet = monet_discriminator(fake_monet.detach())\n",
    "        \n",
    "        loss_D_monet_real = criterion_gan(pred_real_monet, real_label)\n",
    "        loss_D_monet_fake = criterion_gan(pred_fake_monet, fake_label)\n",
    "        loss_D_monet = (loss_D_monet_real + loss_D_monet_fake) * 0.5\n",
    "        \n",
    "        loss_D_monet.backward()\n",
    "        optimizer_D_monet.step()\n",
    "        \n",
    "        # Photo判别器\n",
    "        optimizer_D_photo.zero_grad()\n",
    "        \n",
    "        pred_real_photo = photo_discriminator(real_photo)\n",
    "        pred_fake_photo = photo_discriminator(fake_photo.detach())\n",
    "        \n",
    "        loss_D_photo_real = criterion_gan(pred_real_photo, real_label)\n",
    "        loss_D_photo_fake = criterion_gan(pred_fake_photo, fake_label)\n",
    "        loss_D_photo = (loss_D_photo_real + loss_D_photo_fake) * 0.5\n",
    "        \n",
    "        loss_D_photo.backward()\n",
    "        optimizer_D_photo.step()\n",
    "        \n",
    "        # 累计损失\n",
    "        total_loss_G += loss_G.item()\n",
    "        total_loss_D_monet += loss_D_monet.item()\n",
    "        total_loss_D_photo += loss_D_photo.item()\n",
    "        \n",
    "        # 打印进度\n",
    "        if step % 50 == 0:\n",
    "            print(f\"Step {step}: G_loss={loss_G.item():.4f}, D_monet={loss_D_monet.item():.4f}, D_photo={loss_D_photo.item():.4f}\")\n",
    "    \n",
    "    return total_loss_G / steps, total_loss_D_monet / steps, total_loss_D_photo / steps\n",
    "\n",
    "print(\"✅ 训练函数定义完成\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 开始训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型将保存到: saves\\pytorch_cyclegan_monet_20251026_203754\n",
      "🚀 开始训练...\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|                                                                                  | 0/38 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# 训练一个epoch\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     avg_loss_G, avg_loss_D_monet, avg_loss_D_photo \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonet_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphoto_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# 记录历史\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(avg_loss_G)\n",
      "Cell \u001b[1;32mIn[7], line 36\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(monet_loader, photo_loader, epoch)\u001b[0m\n\u001b[0;32m     33\u001b[0m optimizer_G\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Identity loss\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m loss_identity_monet \u001b[38;5;241m=\u001b[39m criterion_identity(\u001b[43mmonet_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_monet\u001b[49m\u001b[43m)\u001b[49m, real_monet)\n\u001b[0;32m     37\u001b[0m loss_identity_photo \u001b[38;5;241m=\u001b[39m criterion_identity(photo_generator(real_photo), real_photo)\n\u001b[0;32m     38\u001b[0m loss_identity \u001b[38;5;241m=\u001b[39m (loss_identity_monet \u001b[38;5;241m+\u001b[39m loss_identity_photo) \u001b[38;5;241m*\u001b[39m LAMBDA_IDENTITY\n",
      "File \u001b[1;32mD:\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[5], line 92\u001b[0m, in \u001b[0;36mGenerator.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# 下采样\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m     d1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m     d2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown1(d1)\n\u001b[0;32m     94\u001b[0m     d3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown2(d2)\n",
      "File \u001b[1;32mD:\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mD:\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mD:\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mD:\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# 创建保存目录\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "save_dir = os.path.join(SAVE_DIR, f\"{MODEL_NAME}_{timestamp}\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "print(f\"模型将保存到: {save_dir}\")\n",
    "\n",
    "# 训练历史\n",
    "history = {\n",
    "    'G_loss': [],\n",
    "    'D_monet_loss': [],\n",
    "    'D_photo_loss': []\n",
    "}\n",
    "\n",
    "print(\"🚀 开始训练...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # 训练一个epoch\n",
    "    avg_loss_G, avg_loss_D_monet, avg_loss_D_photo = train_epoch(monet_loader, photo_loader, epoch)\n",
    "    \n",
    "    # 记录历史\n",
    "    history['G_loss'].append(avg_loss_G)\n",
    "    history['D_monet_loss'].append(avg_loss_D_monet)\n",
    "    history['D_photo_loss'].append(avg_loss_D_photo)\n",
    "    \n",
    "    # 更新学习率\n",
    "    scheduler_G.step()\n",
    "    scheduler_D_monet.step()\n",
    "    scheduler_D_photo.step()\n",
    "    \n",
    "    # 打印epoch结果\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}:\")\n",
    "    print(f\"  G_loss: {avg_loss_G:.4f}\")\n",
    "    print(f\"  D_monet_loss: {avg_loss_D_monet:.4f}\")\n",
    "    print(f\"  D_photo_loss: {avg_loss_D_photo:.4f}\")\n",
    "    print(f\"  Learning Rate: {scheduler_G.get_last_lr()[0]:.6f}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # 保存checkpoint\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'monet_generator': monet_generator.state_dict(),\n",
    "            'photo_generator': photo_generator.state_dict(),\n",
    "            'monet_discriminator': monet_discriminator.state_dict(),\n",
    "            'photo_discriminator': photo_discriminator.state_dict(),\n",
    "            'optimizer_G': optimizer_G.state_dict(),\n",
    "            'optimizer_D_monet': optimizer_D_monet.state_dict(),\n",
    "            'optimizer_D_photo': optimizer_D_photo.state_dict(),\n",
    "            'history': history\n",
    "        }\n",
    "        torch.save(checkpoint, os.path.join(save_dir, f'checkpoint_epoch_{epoch+1}.pth'))\n",
    "\n",
    "print(\"✅ 训练完成！\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
